{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import catboost as cat\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import log_loss, confusion_matrix, accuracy_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing files\n",
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "sample = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(data):\n",
    "    \n",
    "    '''\n",
    "    Function to input missing values based on the column object type\n",
    "    '''\n",
    "    \n",
    "    cols = list(data.columns)\n",
    "    for col in cols:\n",
    "        if data[col].dtype == 'int64' or data[col].dtype == 'float64':\n",
    "        \n",
    "            data[col] = data[col].fillna(data[col].mean())\n",
    "        \n",
    "        #elif data[col].dtype == 'O' or data[col].dtype == 'object':\n",
    "        #    data[col] = data[col].fillna(data[col].mode()[0])\n",
    "            \n",
    "        else:\n",
    "            data[col] = data[col].fillna(data[col].mode()[0])\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_encoding(traindata, testdata, *args):\n",
    "    \n",
    "    for _ in args:\n",
    "        train_enc = (traindata.groupby(_).size()) / len(traindata)\n",
    "        test_enc = (testdata.groupby(_).size()) / len(testdata)\n",
    "        \n",
    "        traindata[_] = traindata[_].apply(lambda x: train_enc[x])\n",
    "        testdata[_] = testdata[_].apply(lambda x: test_enc[x])\n",
    "    \n",
    "    return traindata, testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(traindata, testdata, *args):\n",
    "    \n",
    "    for ii in args:\n",
    "        traindata = pd.get_dummies(traindata, prefix=[ii], columns=[ii])\n",
    "        testdata = pd.get_dummies(testdata, prefix=[ii], columns=[ii])\n",
    "        \n",
    "    return traindata, testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(traindata, testdata, target, *args):\n",
    "    \n",
    "    labels = np.array(traindata[target])\n",
    "    \n",
    "    columns = []\n",
    "    for _ in args:\n",
    "        columns.append(_)\n",
    "        \n",
    "    traindata = traindata.drop(columns, axis=1)\n",
    "    traindata = traindata.drop(target, axis=1)\n",
    "    testdata = testdata.drop(columns, axis=1)\n",
    "        \n",
    "    return labels, traindata, testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_encoding(traindata, testdata, *args):\n",
    "    for _ in args:\n",
    "        mean_encode = traindata.groupby(_)['CHURN'].mean()\n",
    "        traindata[:, _ + '_mean_enc'] = traindata[_].map(mean_encode)\n",
    "        \n",
    "    for _ in args:\n",
    "        mean_encode = testdata.groupby(_)['CHURN'].mean()\n",
    "        testdata[:, _ + '_mean_enc'] = testdata[_].map(mean_encode)\n",
    "        \n",
    "    return traindata, testdata\n",
    "\n",
    "def mean_encode1(traindata, testdata, *args):\n",
    "    for _ in args:\n",
    "        ce_TE = ce.TargetEncoder(cols=[_])\n",
    "        ce_TE.fit(traindata[_],traindata.CHURN)\n",
    "        ce_TE.transform(traindata[_])\n",
    "        \n",
    "    for _ in args:\n",
    "        ce_TE = ce.TargetEncoder(cols=[_])\n",
    "        ce_TE.fit(testdata[_],testdata.CHURN)\n",
    "        ce_TE.transform(testdata[_])\n",
    "        \n",
    "    return traindata, testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install category_encoders\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(traindata, testdata, args):\n",
    "    \n",
    "    cols = list(args)\n",
    "    for i in cols:\n",
    "        for j in cols:\n",
    "            traindata[i + '+' + j] = traindata[i] + traindata[j]\n",
    "            traindata[i + '-' + j] = traindata[i] - traindata[j]\n",
    "            traindata[i + '/' + j] = traindata[i] / traindata[j]\n",
    "            traindata[i + '*' + j] = traindata[i] * traindata[j]\n",
    "            \n",
    "            traindata = traindata.drop([i + '+' + i])\n",
    "            traindata = traindata.drop([i + '-' + i])\n",
    "            traindata = traindata.drop([i + '/' + i])\n",
    "            traindata = traindata.drop([i + '*' + i])\n",
    "            \n",
    "            testdata[i + '+' + j] = testdata[i] + testdata[j]\n",
    "            testdata[i + '-' + j] = testdata[i] - testdata[j]\n",
    "            testdata[i + '/' + j] = testdata[i] / testdata[j]\n",
    "            testdata[i + '*' + j] = testdata[i] * testdata[j]\n",
    "            \n",
    "            testdata = testdata.drop([i + '+' + i])\n",
    "            testdata = testdata.drop([i + '-' + i])\n",
    "            testdata = testdata.drop([i + '/' + i])\n",
    "            testdata = testdata.drop([i + '*' + i])\n",
    "            \n",
    "    return traindata, testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ZONE1', 'ZONE2', 'TIGO', 'user_id', 'MRG']\n",
    "\n",
    "labels, train1, test1 = drop_columns(train, test, 'CHURN', *cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = ['REGION', 'TENURE']\n",
    "\n",
    "train1, test1 = one_hot_encoding(train1, test1, *one_hot_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train1.fillna(-999)\n",
    "test1 = test1.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = fill_missing_values(train1)\n",
    "test1 = fill_missing_values(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_col = ['TOP_PACK']\n",
    "\n",
    "train1, test1 = freq_encoding(train1, test1, *freq_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_encode_cols = ['REGION', 'TENURE']\n",
    "#train1, test1 = mean_encode1(train, test, mean_encode_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTANT</th>\n",
       "      <th>FREQUENCE_RECH</th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>ARPU_SEGMENT</th>\n",
       "      <th>FREQUENCE</th>\n",
       "      <th>DATA_VOLUME</th>\n",
       "      <th>ON_NET</th>\n",
       "      <th>ORANGE</th>\n",
       "      <th>REGULARITY</th>\n",
       "      <th>TOP_PACK</th>\n",
       "      <th>...</th>\n",
       "      <th>REGION_THIES</th>\n",
       "      <th>REGION_ZIGUINCHOR</th>\n",
       "      <th>TENURE_D 3-6 month</th>\n",
       "      <th>TENURE_E 6-9 month</th>\n",
       "      <th>TENURE_F 9-12 month</th>\n",
       "      <th>TENURE_G 12-15 month</th>\n",
       "      <th>TENURE_H 15-18 month</th>\n",
       "      <th>TENURE_I 18-21 month</th>\n",
       "      <th>TENURE_J 21-24 month</th>\n",
       "      <th>TENURE_K &gt; 24 month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.146687</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4300.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4427.0</td>\n",
       "      <td>1476.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.038975</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.146687</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2497.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.070968</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.418322</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTANT  FREQUENCE_RECH  REVENUE  ARPU_SEGMENT  FREQUENCE  DATA_VOLUME  \\\n",
       "0  17000.0            32.0  18000.0        6000.0       34.0       -999.0   \n",
       "1   4300.0            29.0   4427.0        1476.0       37.0       1764.0   \n",
       "2   1500.0             3.0   1500.0         500.0        3.0       -999.0   \n",
       "3   1500.0             3.0   2497.0         832.0        4.0          0.0   \n",
       "4   -999.0          -999.0    498.0         166.0        3.0          1.0   \n",
       "\n",
       "   ON_NET  ORANGE  REGULARITY  TOP_PACK  ...  REGION_THIES  REGION_ZIGUINCHOR  \\\n",
       "0    97.0   355.0          62  0.146687  ...             0                  0   \n",
       "1     8.0     3.0          40  0.038975  ...             0                  0   \n",
       "2    30.0    30.0          32  0.146687  ...             0                  0   \n",
       "3   159.0    45.0          18  0.070968  ...             0                  0   \n",
       "4     1.0     3.0          50  0.418322  ...             0                  0   \n",
       "\n",
       "   TENURE_D 3-6 month  TENURE_E 6-9 month  TENURE_F 9-12 month  \\\n",
       "0                   0                   0                    0   \n",
       "1                   0                   0                    0   \n",
       "2                   0                   0                    0   \n",
       "3                   0                   0                    0   \n",
       "4                   0                   0                    0   \n",
       "\n",
       "   TENURE_G 12-15 month  TENURE_H 15-18 month  TENURE_I 18-21 month  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   TENURE_J 21-24 month  TENURE_K > 24 month  \n",
       "0                     0                    1  \n",
       "1                     0                    1  \n",
       "2                     0                    1  \n",
       "3                     0                    1  \n",
       "4                     0                    1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTANT</th>\n",
       "      <th>FREQUENCE_RECH</th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>ARPU_SEGMENT</th>\n",
       "      <th>FREQUENCE</th>\n",
       "      <th>DATA_VOLUME</th>\n",
       "      <th>ON_NET</th>\n",
       "      <th>ORANGE</th>\n",
       "      <th>REGULARITY</th>\n",
       "      <th>TOP_PACK</th>\n",
       "      <th>...</th>\n",
       "      <th>REGION_THIES</th>\n",
       "      <th>REGION_ZIGUINCHOR</th>\n",
       "      <th>TENURE_D 3-6 month</th>\n",
       "      <th>TENURE_E 6-9 month</th>\n",
       "      <th>TENURE_F 9-12 month</th>\n",
       "      <th>TENURE_G 12-15 month</th>\n",
       "      <th>TENURE_H 15-18 month</th>\n",
       "      <th>TENURE_I 18-21 month</th>\n",
       "      <th>TENURE_J 21-24 month</th>\n",
       "      <th>TENURE_K &gt; 24 month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3235.764910</td>\n",
       "      <td>-342.872347</td>\n",
       "      <td>3315.703170</td>\n",
       "      <td>881.023860</td>\n",
       "      <td>-327.065997</td>\n",
       "      <td>1219.742045</td>\n",
       "      <td>-188.850433</td>\n",
       "      <td>-359.565655</td>\n",
       "      <td>28.046502</td>\n",
       "      <td>0.210899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083435</td>\n",
       "      <td>0.010030</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>0.006970</td>\n",
       "      <td>0.012145</td>\n",
       "      <td>0.020780</td>\n",
       "      <td>0.005812</td>\n",
       "      <td>0.948597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6512.606182</td>\n",
       "      <td>482.318318</td>\n",
       "      <td>6603.421492</td>\n",
       "      <td>2364.108984</td>\n",
       "      <td>478.837134</td>\n",
       "      <td>9021.014027</td>\n",
       "      <td>928.163148</td>\n",
       "      <td>561.688367</td>\n",
       "      <td>22.282773</td>\n",
       "      <td>0.180485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276539</td>\n",
       "      <td>0.099646</td>\n",
       "      <td>0.019232</td>\n",
       "      <td>0.029945</td>\n",
       "      <td>0.066392</td>\n",
       "      <td>0.083195</td>\n",
       "      <td>0.109533</td>\n",
       "      <td>0.142647</td>\n",
       "      <td>0.076018</td>\n",
       "      <td>0.220818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.146687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4600.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4698.000000</td>\n",
       "      <td>1566.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.418322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>226550.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>233413.000000</td>\n",
       "      <td>77804.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>934576.000000</td>\n",
       "      <td>45011.000000</td>\n",
       "      <td>6788.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.418322</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             MONTANT  FREQUENCE_RECH        REVENUE   ARPU_SEGMENT  \\\n",
       "count  400000.000000   400000.000000  400000.000000  400000.000000   \n",
       "mean     3235.764910     -342.872347    3315.703170     881.023860   \n",
       "std      6512.606182      482.318318    6603.421492    2364.108984   \n",
       "min      -999.000000     -999.000000    -999.000000    -999.000000   \n",
       "25%      -999.000000     -999.000000    -999.000000    -999.000000   \n",
       "50%      1000.000000        2.000000    1000.000000     333.000000   \n",
       "75%      4600.000000       10.000000    4698.000000    1566.000000   \n",
       "max    226550.000000      133.000000  233413.000000   77804.000000   \n",
       "\n",
       "           FREQUENCE    DATA_VOLUME         ON_NET         ORANGE  \\\n",
       "count  400000.000000  400000.000000  400000.000000  400000.000000   \n",
       "mean     -327.065997    1219.742045    -188.850433    -359.565655   \n",
       "std       478.837134    9021.014027     928.163148     561.688367   \n",
       "min      -999.000000    -999.000000    -999.000000    -999.000000   \n",
       "25%      -999.000000    -999.000000    -999.000000    -999.000000   \n",
       "50%         3.000000       0.000000       3.000000       3.000000   \n",
       "75%        13.000000     301.000000      55.000000      41.000000   \n",
       "max        91.000000  934576.000000   45011.000000    6788.000000   \n",
       "\n",
       "          REGULARITY       TOP_PACK  ...   REGION_THIES  REGION_ZIGUINCHOR  \\\n",
       "count  400000.000000  400000.000000  ...  400000.000000      400000.000000   \n",
       "mean       28.046502       0.210899  ...       0.083435           0.010030   \n",
       "std        22.282773       0.180485  ...       0.276539           0.099646   \n",
       "min         1.000000       0.000003  ...       0.000000           0.000000   \n",
       "25%         6.000000       0.031780  ...       0.000000           0.000000   \n",
       "50%        24.000000       0.146687  ...       0.000000           0.000000   \n",
       "75%        51.000000       0.418322  ...       0.000000           0.000000   \n",
       "max        62.000000       0.418322  ...       1.000000           1.000000   \n",
       "\n",
       "       TENURE_D 3-6 month  TENURE_E 6-9 month  TENURE_F 9-12 month  \\\n",
       "count       400000.000000       400000.000000        400000.000000   \n",
       "mean             0.000370            0.000897             0.004428   \n",
       "std              0.019232            0.029945             0.066392   \n",
       "min              0.000000            0.000000             0.000000   \n",
       "25%              0.000000            0.000000             0.000000   \n",
       "50%              0.000000            0.000000             0.000000   \n",
       "75%              0.000000            0.000000             0.000000   \n",
       "max              1.000000            1.000000             1.000000   \n",
       "\n",
       "       TENURE_G 12-15 month  TENURE_H 15-18 month  TENURE_I 18-21 month  \\\n",
       "count         400000.000000         400000.000000         400000.000000   \n",
       "mean               0.006970              0.012145              0.020780   \n",
       "std                0.083195              0.109533              0.142647   \n",
       "min                0.000000              0.000000              0.000000   \n",
       "25%                0.000000              0.000000              0.000000   \n",
       "50%                0.000000              0.000000              0.000000   \n",
       "75%                0.000000              0.000000              0.000000   \n",
       "max                1.000000              1.000000              1.000000   \n",
       "\n",
       "       TENURE_J 21-24 month  TENURE_K > 24 month  \n",
       "count         400000.000000        400000.000000  \n",
       "mean               0.005812             0.948597  \n",
       "std                0.076018             0.220818  \n",
       "min                0.000000             0.000000  \n",
       "25%                0.000000             1.000000  \n",
       "50%                0.000000             1.000000  \n",
       "75%                0.000000             1.000000  \n",
       "max                1.000000             1.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olawale/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:679: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/olawale/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:679: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train1['REG*REV'] = train1['REGULARITY'] * train1['REVENUE']\n",
    "train1['REG/REV'] = train1['REGULARITY'] / train1['REVENUE']\n",
    "train1['LOG_REV'] = np.log(train1['REVENUE'])\n",
    "train1['REG*MUT'] = train1['REGULARITY'] * train1['MONTANT']\n",
    "train1['REG/MUT'] = train1['REGULARITY'] / train1['MONTANT']\n",
    "train1['LOG_MUT'] = np.log(train1['MONTANT'])\n",
    "train1['REG*NET'] = train1['REGULARITY'] * train1['ON_NET']\n",
    "train1['REG/NET'] = train1['REGULARITY'] / train1['ON_NET']\n",
    "train1['FREQ+FREQ'] = train1['FREQUENCE_RECH'] + train1['FREQUENCE']\n",
    "train1['FREQ-FREQ'] = train1['FREQUENCE_RECH'] - train1['FREQUENCE']\n",
    "train1['LOG_NET'] = np.log(train1['ON_NET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olawale/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:679: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/olawale/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:679: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "test1['REG*REV'] = test1['REGULARITY'] * test1['REVENUE']\n",
    "test1['REG/REV'] = test1['REGULARITY'] / test1['REVENUE']\n",
    "test1['LOG_REV'] = np.log(test1['REVENUE'])\n",
    "test1['REG*MUT'] = test1['REGULARITY'] * test1['MONTANT']\n",
    "test1['REG/MUT'] = test1['REGULARITY'] / test1['MONTANT']\n",
    "test1['LOG_MUT'] = np.log(test1['MONTANT'])\n",
    "test1['REG*NET'] = test1['REGULARITY'] * test1['ON_NET']\n",
    "test1['REG/NET'] = test1['REGULARITY'] / test1['ON_NET']\n",
    "test1['FREQ+FREQ'] = test1['FREQUENCE_RECH'] + test1['FREQUENCE']\n",
    "test1['FREQ-FREQ'] = test1['FREQUENCE_RECH'] - test1['FREQUENCE']\n",
    "test1['LOG_NET'] = np.log(test1['ON_NET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTANT</th>\n",
       "      <th>FREQUENCE_RECH</th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>ARPU_SEGMENT</th>\n",
       "      <th>FREQUENCE</th>\n",
       "      <th>DATA_VOLUME</th>\n",
       "      <th>ON_NET</th>\n",
       "      <th>ORANGE</th>\n",
       "      <th>REGULARITY</th>\n",
       "      <th>TOP_PACK</th>\n",
       "      <th>...</th>\n",
       "      <th>REG/REV</th>\n",
       "      <th>LOG_REV</th>\n",
       "      <th>REG*MUT</th>\n",
       "      <th>REG/MUT</th>\n",
       "      <th>LOG_MUT</th>\n",
       "      <th>REG*NET</th>\n",
       "      <th>REG/NET</th>\n",
       "      <th>FREQ+FREQ</th>\n",
       "      <th>FREQ-FREQ</th>\n",
       "      <th>LOG_NET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>265337.000000</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>259723.000000</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.00000</td>\n",
       "      <td>2.541810e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3235.764910</td>\n",
       "      <td>-342.872347</td>\n",
       "      <td>3315.703170</td>\n",
       "      <td>881.023860</td>\n",
       "      <td>-327.065997</td>\n",
       "      <td>1219.742045</td>\n",
       "      <td>-188.850433</td>\n",
       "      <td>-359.565655</td>\n",
       "      <td>28.046502</td>\n",
       "      <td>0.210899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060019</td>\n",
       "      <td>7.787373</td>\n",
       "      <td>1.822993e+05</td>\n",
       "      <td>0.010379</td>\n",
       "      <td>7.909051</td>\n",
       "      <td>6.036214e+03</td>\n",
       "      <td>inf</td>\n",
       "      <td>-669.938345</td>\n",
       "      <td>-15.80635</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6512.606182</td>\n",
       "      <td>482.318318</td>\n",
       "      <td>6603.421492</td>\n",
       "      <td>2364.108984</td>\n",
       "      <td>478.837134</td>\n",
       "      <td>9021.014027</td>\n",
       "      <td>928.163148</td>\n",
       "      <td>561.688367</td>\n",
       "      <td>22.282773</td>\n",
       "      <td>0.180485</td>\n",
       "      <td>...</td>\n",
       "      <td>1.038109</td>\n",
       "      <td>1.572457</td>\n",
       "      <td>3.778982e+05</td>\n",
       "      <td>0.033682</td>\n",
       "      <td>1.298821</td>\n",
       "      <td>4.398344e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>943.008384</td>\n",
       "      <td>185.92232</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.193800e+04</td>\n",
       "      <td>-0.062062</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>-6.193800e+04</td>\n",
       "      <td>-6.206206e-02</td>\n",
       "      <td>-1998.000000</td>\n",
       "      <td>-1085.00000</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002002</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>-1.998000e+03</td>\n",
       "      <td>-0.002002</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>-1.998000e+03</td>\n",
       "      <td>-2.002002e-03</td>\n",
       "      <td>-1998.000000</td>\n",
       "      <td>-3.00000</td>\n",
       "      <td>1.609438e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.146687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005631</td>\n",
       "      <td>8.006368</td>\n",
       "      <td>2.000000e+04</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>8.006368</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>1.992481e-01</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.295837e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4600.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4698.000000</td>\n",
       "      <td>1566.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.418322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014381</td>\n",
       "      <td>8.901094</td>\n",
       "      <td>2.050000e+05</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>8.895630</td>\n",
       "      <td>2.128000e+03</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.043425e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>226550.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>233413.000000</td>\n",
       "      <td>77804.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>934576.000000</td>\n",
       "      <td>45011.000000</td>\n",
       "      <td>6788.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.418322</td>\n",
       "      <td>...</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>12.360565</td>\n",
       "      <td>1.404610e+07</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>12.330721</td>\n",
       "      <td>2.790682e+06</td>\n",
       "      <td>inf</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>1004.00000</td>\n",
       "      <td>1.071466e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             MONTANT  FREQUENCE_RECH        REVENUE   ARPU_SEGMENT  \\\n",
       "count  400000.000000   400000.000000  400000.000000  400000.000000   \n",
       "mean     3235.764910     -342.872347    3315.703170     881.023860   \n",
       "std      6512.606182      482.318318    6603.421492    2364.108984   \n",
       "min      -999.000000     -999.000000    -999.000000    -999.000000   \n",
       "25%      -999.000000     -999.000000    -999.000000    -999.000000   \n",
       "50%      1000.000000        2.000000    1000.000000     333.000000   \n",
       "75%      4600.000000       10.000000    4698.000000    1566.000000   \n",
       "max    226550.000000      133.000000  233413.000000   77804.000000   \n",
       "\n",
       "           FREQUENCE    DATA_VOLUME         ON_NET         ORANGE  \\\n",
       "count  400000.000000  400000.000000  400000.000000  400000.000000   \n",
       "mean     -327.065997    1219.742045    -188.850433    -359.565655   \n",
       "std       478.837134    9021.014027     928.163148     561.688367   \n",
       "min      -999.000000    -999.000000    -999.000000    -999.000000   \n",
       "25%      -999.000000    -999.000000    -999.000000    -999.000000   \n",
       "50%         3.000000       0.000000       3.000000       3.000000   \n",
       "75%        13.000000     301.000000      55.000000      41.000000   \n",
       "max        91.000000  934576.000000   45011.000000    6788.000000   \n",
       "\n",
       "          REGULARITY       TOP_PACK  ...        REG/REV        LOG_REV  \\\n",
       "count  400000.000000  400000.000000  ...  400000.000000  265337.000000   \n",
       "mean       28.046502       0.210899  ...       0.060019       7.787373   \n",
       "std        22.282773       0.180485  ...       1.038109       1.572457   \n",
       "min         1.000000       0.000003  ...      -0.062062       0.000000   \n",
       "25%         6.000000       0.031780  ...      -0.002002       6.907755   \n",
       "50%        24.000000       0.146687  ...       0.005631       8.006368   \n",
       "75%        51.000000       0.418322  ...       0.014381       8.901094   \n",
       "max        62.000000       0.418322  ...      62.000000      12.360565   \n",
       "\n",
       "            REG*MUT        REG/MUT        LOG_MUT       REG*NET       REG/NET  \\\n",
       "count  4.000000e+05  400000.000000  259723.000000  4.000000e+05  4.000000e+05   \n",
       "mean   1.822993e+05       0.010379       7.909051  6.036214e+03           inf   \n",
       "std    3.778982e+05       0.033682       1.298821  4.398344e+04           NaN   \n",
       "min   -6.193800e+04      -0.062062       2.995732 -6.193800e+04 -6.206206e-02   \n",
       "25%   -1.998000e+03      -0.002002       6.907755 -1.998000e+03 -2.002002e-03   \n",
       "50%    2.000000e+04       0.005333       8.006368  6.000000e+01  1.992481e-01   \n",
       "75%    2.050000e+05       0.013500       8.895630  2.128000e+03  2.000000e+00   \n",
       "max    1.404610e+07       2.050000      12.330721  2.790682e+06           inf   \n",
       "\n",
       "           FREQ+FREQ     FREQ-FREQ       LOG_NET  \n",
       "count  400000.000000  400000.00000  2.541810e+05  \n",
       "mean     -669.938345     -15.80635          -inf  \n",
       "std       943.008384     185.92232           NaN  \n",
       "min     -1998.000000   -1085.00000          -inf  \n",
       "25%     -1998.000000      -3.00000  1.609438e+00  \n",
       "50%         6.000000       0.00000  3.295837e+00  \n",
       "75%        23.000000       0.00000  5.043425e+00  \n",
       "max       224.000000    1004.00000  1.071466e+01  \n",
       "\n",
       "[8 rows x 44 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(traindata, testdata):\n",
    "    \n",
    "    cols = list(traindata.columns)\n",
    "    for _ in cols:\n",
    "        traindata[_] = np.where(traindata[_] == np.inf, 0, traindata[_])\n",
    "        testdata[_] = np.where(testdata[_] == np.inf, 0, testdata[_])\n",
    "        traindata[_] = np.where(traindata[_] == np.nan, 0, traindata[_])\n",
    "        testdata[_] = np.where(testdata[_] == np.nan, 0, testdata[_])\n",
    "        traindata[_] = np.where(traindata[_] == -np.inf, 0, traindata[_])\n",
    "        testdata[_] = np.where(testdata[_] == -np.inf, 0, testdata[_])\n",
    "        \n",
    "    return traindata, testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1, test1 = process(train1, test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTANT</th>\n",
       "      <th>FREQUENCE_RECH</th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>ARPU_SEGMENT</th>\n",
       "      <th>FREQUENCE</th>\n",
       "      <th>DATA_VOLUME</th>\n",
       "      <th>ON_NET</th>\n",
       "      <th>ORANGE</th>\n",
       "      <th>REGULARITY</th>\n",
       "      <th>TOP_PACK</th>\n",
       "      <th>...</th>\n",
       "      <th>REG/REV</th>\n",
       "      <th>LOG_REV</th>\n",
       "      <th>REG*MUT</th>\n",
       "      <th>REG/MUT</th>\n",
       "      <th>LOG_MUT</th>\n",
       "      <th>REG*NET</th>\n",
       "      <th>REG/NET</th>\n",
       "      <th>FREQ+FREQ</th>\n",
       "      <th>FREQ-FREQ</th>\n",
       "      <th>LOG_NET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>265337.000000</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>259723.000000</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.00000</td>\n",
       "      <td>254181.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3235.764910</td>\n",
       "      <td>-342.872347</td>\n",
       "      <td>3315.703170</td>\n",
       "      <td>881.023860</td>\n",
       "      <td>-327.065997</td>\n",
       "      <td>1219.742045</td>\n",
       "      <td>-188.850433</td>\n",
       "      <td>-359.565655</td>\n",
       "      <td>28.046502</td>\n",
       "      <td>0.210899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060019</td>\n",
       "      <td>7.787373</td>\n",
       "      <td>1.822993e+05</td>\n",
       "      <td>0.010379</td>\n",
       "      <td>7.909051</td>\n",
       "      <td>6.036214e+03</td>\n",
       "      <td>2.493898</td>\n",
       "      <td>-669.938345</td>\n",
       "      <td>-15.80635</td>\n",
       "      <td>3.326560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6512.606182</td>\n",
       "      <td>482.318318</td>\n",
       "      <td>6603.421492</td>\n",
       "      <td>2364.108984</td>\n",
       "      <td>478.837134</td>\n",
       "      <td>9021.014027</td>\n",
       "      <td>928.163148</td>\n",
       "      <td>561.688367</td>\n",
       "      <td>22.282773</td>\n",
       "      <td>0.180485</td>\n",
       "      <td>...</td>\n",
       "      <td>1.038109</td>\n",
       "      <td>1.572457</td>\n",
       "      <td>3.778982e+05</td>\n",
       "      <td>0.033682</td>\n",
       "      <td>1.298821</td>\n",
       "      <td>4.398344e+04</td>\n",
       "      <td>7.390162</td>\n",
       "      <td>943.008384</td>\n",
       "      <td>185.92232</td>\n",
       "      <td>2.289157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.193800e+04</td>\n",
       "      <td>-0.062062</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>-6.193800e+04</td>\n",
       "      <td>-0.062062</td>\n",
       "      <td>-1998.000000</td>\n",
       "      <td>-1085.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002002</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>-1.998000e+03</td>\n",
       "      <td>-0.002002</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>-1.998000e+03</td>\n",
       "      <td>-0.002002</td>\n",
       "      <td>-1998.000000</td>\n",
       "      <td>-3.00000</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.146687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005631</td>\n",
       "      <td>8.006368</td>\n",
       "      <td>2.000000e+04</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>8.006368</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.105392</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.295837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4600.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4698.000000</td>\n",
       "      <td>1566.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.418322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014381</td>\n",
       "      <td>8.901094</td>\n",
       "      <td>2.050000e+05</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>8.895630</td>\n",
       "      <td>2.128000e+03</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.043425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>226550.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>233413.000000</td>\n",
       "      <td>77804.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>934576.000000</td>\n",
       "      <td>45011.000000</td>\n",
       "      <td>6788.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.418322</td>\n",
       "      <td>...</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>12.360565</td>\n",
       "      <td>1.404610e+07</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>12.330721</td>\n",
       "      <td>2.790682e+06</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>1004.00000</td>\n",
       "      <td>10.714662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             MONTANT  FREQUENCE_RECH        REVENUE   ARPU_SEGMENT  \\\n",
       "count  400000.000000   400000.000000  400000.000000  400000.000000   \n",
       "mean     3235.764910     -342.872347    3315.703170     881.023860   \n",
       "std      6512.606182      482.318318    6603.421492    2364.108984   \n",
       "min      -999.000000     -999.000000    -999.000000    -999.000000   \n",
       "25%      -999.000000     -999.000000    -999.000000    -999.000000   \n",
       "50%      1000.000000        2.000000    1000.000000     333.000000   \n",
       "75%      4600.000000       10.000000    4698.000000    1566.000000   \n",
       "max    226550.000000      133.000000  233413.000000   77804.000000   \n",
       "\n",
       "           FREQUENCE    DATA_VOLUME         ON_NET         ORANGE  \\\n",
       "count  400000.000000  400000.000000  400000.000000  400000.000000   \n",
       "mean     -327.065997    1219.742045    -188.850433    -359.565655   \n",
       "std       478.837134    9021.014027     928.163148     561.688367   \n",
       "min      -999.000000    -999.000000    -999.000000    -999.000000   \n",
       "25%      -999.000000    -999.000000    -999.000000    -999.000000   \n",
       "50%         3.000000       0.000000       3.000000       3.000000   \n",
       "75%        13.000000     301.000000      55.000000      41.000000   \n",
       "max        91.000000  934576.000000   45011.000000    6788.000000   \n",
       "\n",
       "          REGULARITY       TOP_PACK  ...        REG/REV        LOG_REV  \\\n",
       "count  400000.000000  400000.000000  ...  400000.000000  265337.000000   \n",
       "mean       28.046502       0.210899  ...       0.060019       7.787373   \n",
       "std        22.282773       0.180485  ...       1.038109       1.572457   \n",
       "min         1.000000       0.000003  ...      -0.062062       0.000000   \n",
       "25%         6.000000       0.031780  ...      -0.002002       6.907755   \n",
       "50%        24.000000       0.146687  ...       0.005631       8.006368   \n",
       "75%        51.000000       0.418322  ...       0.014381       8.901094   \n",
       "max        62.000000       0.418322  ...      62.000000      12.360565   \n",
       "\n",
       "            REG*MUT        REG/MUT        LOG_MUT       REG*NET  \\\n",
       "count  4.000000e+05  400000.000000  259723.000000  4.000000e+05   \n",
       "mean   1.822993e+05       0.010379       7.909051  6.036214e+03   \n",
       "std    3.778982e+05       0.033682       1.298821  4.398344e+04   \n",
       "min   -6.193800e+04      -0.062062       2.995732 -6.193800e+04   \n",
       "25%   -1.998000e+03      -0.002002       6.907755 -1.998000e+03   \n",
       "50%    2.000000e+04       0.005333       8.006368  6.000000e+01   \n",
       "75%    2.050000e+05       0.013500       8.895630  2.128000e+03   \n",
       "max    1.404610e+07       2.050000      12.330721  2.790682e+06   \n",
       "\n",
       "             REG/NET      FREQ+FREQ     FREQ-FREQ        LOG_NET  \n",
       "count  400000.000000  400000.000000  400000.00000  254181.000000  \n",
       "mean        2.493898    -669.938345     -15.80635       3.326560  \n",
       "std         7.390162     943.008384     185.92232       2.289157  \n",
       "min        -0.062062   -1998.000000   -1085.00000       0.000000  \n",
       "25%        -0.002002   -1998.000000      -3.00000       1.609438  \n",
       "50%         0.105392       6.000000       0.00000       3.295837  \n",
       "75%         1.250000      23.000000       0.00000       5.043425  \n",
       "max        62.000000     224.000000    1004.00000      10.714662  \n",
       "\n",
       "[8 rows x 44 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_interact(train, cols):\n",
    "    for i in cols:\n",
    "        for j in cols: train[i + '/' + j] = train[i] / train[j]\n",
    "\n",
    "    for i in cols:\n",
    "        for j in cols: train[i + '+' + j] = train[i] + train[j]\n",
    "\n",
    "    for i in cols:\n",
    "        for j in cols: train[i + '-' + j] = train[i] - train[j]\n",
    "\n",
    "    for i in cols:\n",
    "        for j in cols: train[i + '*' + j] = train[i] * train[j]\n",
    "            \n",
    "    if i in list(train.columns):\n",
    "        if train[i].min() == 0 and train[i].max() == 0:\n",
    "            train = train.drop(i, axis=1)\n",
    "            \n",
    "    return train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['REVENUE', 'ARPU_SEGMENT', 'FREQUENCE', 'REGULARITY']\n",
    "\n",
    "train1 = feature_interact(train1, feature_cols)\n",
    "test1 = feature_interact(test1, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTANT</th>\n",
       "      <th>FREQUENCE_RECH</th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>ARPU_SEGMENT</th>\n",
       "      <th>FREQUENCE</th>\n",
       "      <th>DATA_VOLUME</th>\n",
       "      <th>ON_NET</th>\n",
       "      <th>ORANGE</th>\n",
       "      <th>REGULARITY</th>\n",
       "      <th>TOP_PACK</th>\n",
       "      <th>...</th>\n",
       "      <th>FREQ_TOP_PACK*FREQUENCE_RECH</th>\n",
       "      <th>FREQ_TOP_PACK*REVENUE</th>\n",
       "      <th>FREQ_TOP_PACK*ARPU_SEGMENT</th>\n",
       "      <th>FREQ_TOP_PACK*FREQUENCE</th>\n",
       "      <th>FREQ_TOP_PACK*DATA_VOLUME</th>\n",
       "      <th>FREQ_TOP_PACK*ON_NET</th>\n",
       "      <th>FREQ_TOP_PACK*ORANGE</th>\n",
       "      <th>FREQ_TOP_PACK*REGULARITY</th>\n",
       "      <th>FREQ_TOP_PACK*TOP_PACK</th>\n",
       "      <th>FREQ_TOP_PACK*FREQ_TOP_PACK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3235.764910</td>\n",
       "      <td>-342.872347</td>\n",
       "      <td>3315.703170</td>\n",
       "      <td>881.023860</td>\n",
       "      <td>-327.065997</td>\n",
       "      <td>1219.742045</td>\n",
       "      <td>-188.850433</td>\n",
       "      <td>-359.565655</td>\n",
       "      <td>28.046502</td>\n",
       "      <td>0.210899</td>\n",
       "      <td>...</td>\n",
       "      <td>346610.016187</td>\n",
       "      <td>3.368942e+05</td>\n",
       "      <td>3.362632e+05</td>\n",
       "      <td>335766.023155</td>\n",
       "      <td>3.041744e+05</td>\n",
       "      <td>3.167492e+05</td>\n",
       "      <td>3.576385e+05</td>\n",
       "      <td>-4074.945715</td>\n",
       "      <td>-174.489506</td>\n",
       "      <td>417624.169632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6512.606182</td>\n",
       "      <td>482.318318</td>\n",
       "      <td>6603.421492</td>\n",
       "      <td>2364.108984</td>\n",
       "      <td>478.837134</td>\n",
       "      <td>9021.014027</td>\n",
       "      <td>928.163148</td>\n",
       "      <td>561.688367</td>\n",
       "      <td>22.282773</td>\n",
       "      <td>0.180485</td>\n",
       "      <td>...</td>\n",
       "      <td>475207.162700</td>\n",
       "      <td>9.824639e+05</td>\n",
       "      <td>5.520954e+05</td>\n",
       "      <td>471744.415197</td>\n",
       "      <td>2.258445e+06</td>\n",
       "      <td>4.642740e+05</td>\n",
       "      <td>4.790895e+05</td>\n",
       "      <td>10071.367158</td>\n",
       "      <td>206.426297</td>\n",
       "      <td>492182.376945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>-85914.000000</td>\n",
       "      <td>-1.152217e+08</td>\n",
       "      <td>-3.840755e+07</td>\n",
       "      <td>-88911.000000</td>\n",
       "      <td>-7.195887e+08</td>\n",
       "      <td>-7.433559e+06</td>\n",
       "      <td>-3.536460e+06</td>\n",
       "      <td>-61938.000000</td>\n",
       "      <td>-417.904178</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000e+03</td>\n",
       "      <td>1.334000e+03</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>-2997.000000</td>\n",
       "      <td>-417.904178</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.146687</td>\n",
       "      <td>...</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>7.197150e+04</td>\n",
       "      <td>2.399000e+04</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>4.124000e+03</td>\n",
       "      <td>7.260000e+02</td>\n",
       "      <td>8.960000e+02</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.028012</td>\n",
       "      <td>361.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4600.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4698.000000</td>\n",
       "      <td>1566.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.418322</td>\n",
       "      <td>...</td>\n",
       "      <td>998001.000000</td>\n",
       "      <td>9.980010e+05</td>\n",
       "      <td>9.980010e+05</td>\n",
       "      <td>998001.000000</td>\n",
       "      <td>9.980010e+05</td>\n",
       "      <td>9.980010e+05</td>\n",
       "      <td>9.980010e+05</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>0.283870</td>\n",
       "      <td>998001.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>226550.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>233413.000000</td>\n",
       "      <td>77804.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>934576.000000</td>\n",
       "      <td>45011.000000</td>\n",
       "      <td>6788.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.418322</td>\n",
       "      <td>...</td>\n",
       "      <td>998001.000000</td>\n",
       "      <td>3.991362e+07</td>\n",
       "      <td>1.330448e+07</td>\n",
       "      <td>998001.000000</td>\n",
       "      <td>2.557974e+07</td>\n",
       "      <td>4.821150e+06</td>\n",
       "      <td>9.980010e+05</td>\n",
       "      <td>34595.000000</td>\n",
       "      <td>37.111937</td>\n",
       "      <td>998001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 517 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             MONTANT  FREQUENCE_RECH        REVENUE   ARPU_SEGMENT  \\\n",
       "count  400000.000000   400000.000000  400000.000000  400000.000000   \n",
       "mean     3235.764910     -342.872347    3315.703170     881.023860   \n",
       "std      6512.606182      482.318318    6603.421492    2364.108984   \n",
       "min      -999.000000     -999.000000    -999.000000    -999.000000   \n",
       "25%      -999.000000     -999.000000    -999.000000    -999.000000   \n",
       "50%      1000.000000        2.000000    1000.000000     333.000000   \n",
       "75%      4600.000000       10.000000    4698.000000    1566.000000   \n",
       "max    226550.000000      133.000000  233413.000000   77804.000000   \n",
       "\n",
       "           FREQUENCE    DATA_VOLUME         ON_NET         ORANGE  \\\n",
       "count  400000.000000  400000.000000  400000.000000  400000.000000   \n",
       "mean     -327.065997    1219.742045    -188.850433    -359.565655   \n",
       "std       478.837134    9021.014027     928.163148     561.688367   \n",
       "min      -999.000000    -999.000000    -999.000000    -999.000000   \n",
       "25%      -999.000000    -999.000000    -999.000000    -999.000000   \n",
       "50%         3.000000       0.000000       3.000000       3.000000   \n",
       "75%        13.000000     301.000000      55.000000      41.000000   \n",
       "max        91.000000  934576.000000   45011.000000    6788.000000   \n",
       "\n",
       "          REGULARITY       TOP_PACK  ...  FREQ_TOP_PACK*FREQUENCE_RECH  \\\n",
       "count  400000.000000  400000.000000  ...                 400000.000000   \n",
       "mean       28.046502       0.210899  ...                 346610.016187   \n",
       "std        22.282773       0.180485  ...                 475207.162700   \n",
       "min         1.000000       0.000003  ...                 -85914.000000   \n",
       "25%         6.000000       0.031780  ...                      9.000000   \n",
       "50%        24.000000       0.146687  ...                    170.000000   \n",
       "75%        51.000000       0.418322  ...                 998001.000000   \n",
       "max        62.000000       0.418322  ...                 998001.000000   \n",
       "\n",
       "       FREQ_TOP_PACK*REVENUE  FREQ_TOP_PACK*ARPU_SEGMENT  \\\n",
       "count           4.000000e+05                4.000000e+05   \n",
       "mean            3.368942e+05                3.362632e+05   \n",
       "std             9.824639e+05                5.520954e+05   \n",
       "min            -1.152217e+08               -3.840755e+07   \n",
       "25%             4.000000e+03                1.334000e+03   \n",
       "50%             7.197150e+04                2.399000e+04   \n",
       "75%             9.980010e+05                9.980010e+05   \n",
       "max             3.991362e+07                1.330448e+07   \n",
       "\n",
       "       FREQ_TOP_PACK*FREQUENCE  FREQ_TOP_PACK*DATA_VOLUME  \\\n",
       "count            400000.000000               4.000000e+05   \n",
       "mean             335766.023155               3.041744e+05   \n",
       "std              471744.415197               2.258445e+06   \n",
       "min              -88911.000000              -7.195887e+08   \n",
       "25%                  12.000000               0.000000e+00   \n",
       "50%                 192.000000               4.124000e+03   \n",
       "75%              998001.000000               9.980010e+05   \n",
       "max              998001.000000               2.557974e+07   \n",
       "\n",
       "       FREQ_TOP_PACK*ON_NET  FREQ_TOP_PACK*ORANGE  FREQ_TOP_PACK*REGULARITY  \\\n",
       "count          4.000000e+05          4.000000e+05             400000.000000   \n",
       "mean           3.167492e+05          3.576385e+05              -4074.945715   \n",
       "std            4.642740e+05          4.790895e+05              10071.367158   \n",
       "min           -7.433559e+06         -3.536460e+06             -61938.000000   \n",
       "25%            1.100000e+01          2.400000e+01              -2997.000000   \n",
       "50%            7.260000e+02          8.960000e+02                 24.000000   \n",
       "75%            9.980010e+05          9.980010e+05                255.000000   \n",
       "max            4.821150e+06          9.980010e+05              34595.000000   \n",
       "\n",
       "       FREQ_TOP_PACK*TOP_PACK  FREQ_TOP_PACK*FREQ_TOP_PACK  \n",
       "count           400000.000000                400000.000000  \n",
       "mean              -174.489506                417624.169632  \n",
       "std                206.426297                492182.376945  \n",
       "min               -417.904178                     1.000000  \n",
       "25%               -417.904178                    16.000000  \n",
       "50%                  0.028012                   361.000000  \n",
       "75%                  0.283870                998001.000000  \n",
       "max                 37.111937                998001.000000  \n",
       "\n",
       "[8 rows x 517 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = ms.train_test_split(train1, train.CHURN, test_size=0.3,\n",
    "                                                       random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280000, 44) (280000,)\n",
      "(120000, 44) (120000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1, x_test2,y_test1, y_test2 = ms.train_test_split(x_test, y_test, test_size=0.5,\n",
    "                                                         random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.11347837,  0.77723114,  2.22374343, ...,  0.78041646,\n",
       "         0.07425879,  0.54524581],\n",
       "       [ 0.16341176,  0.77101117,  0.16829127, ...,  0.78041646,\n",
       "         0.04198721, -0.54479474],\n",
       "       [-0.26652419,  0.7171048 , -0.27496434, ...,  0.71679022,\n",
       "         0.08501599,  0.03260482],\n",
       "       ...,\n",
       "       [-0.38936303,  0.71503147, -0.39626525, ...,  0.71785066,\n",
       "         0.0688802 , -1.45318385],\n",
       "       [-0.65024202, -1.36036399, -0.50075666, ..., -0.34788881,\n",
       "        -5.29358111,         nan],\n",
       "       [-0.65024202, -1.36036399, -0.65340499, ..., -1.40832609,\n",
       "         0.08501599,         nan]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using StandardScaler function to scale the numeric features \n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(train1)\n",
    "train1 = scaler.transform(train1)\n",
    "train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.65111099, -1.36390268, -0.65551124, ..., -1.41303086,\n",
       "         0.08806481,         nan],\n",
       "       [-0.65111099, -1.36390268, -0.50292553, ..., -0.3514656 ,\n",
       "        -5.28713855,         nan],\n",
       "       [-0.20772843,  0.73999703, -0.15677221, ...,  0.74619287,\n",
       "         0.05581359,         nan],\n",
       "       ...,\n",
       "       [-0.22302276,  0.72339822, -0.23238455, ...,  0.72496157,\n",
       "         0.0773144 , -1.15392093],\n",
       "       [-0.11596247,  0.71717366, -0.12410768, ...,  0.71646904,\n",
       "         0.08806481,  0.18319156],\n",
       "       [-0.65111099, -1.36390268, -0.65551124, ..., -1.41303086,\n",
       "         0.08806481,         nan]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using StandardScaler function to scale the numeric features \n",
    "\n",
    "scaler1 = preprocessing.StandardScaler().fit(test1)\n",
    "test1 = scaler1.transform(test1)\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.52694\tvalidation_1-logloss:0.52759\n",
      "Multiple eval metrics have been passed: 'validation_1-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-logloss hasn't improved in 30 rounds.\n",
      "[2]\tvalidation_0-logloss:0.37909\tvalidation_1-logloss:0.38079\n",
      "[4]\tvalidation_0-logloss:0.31746\tvalidation_1-logloss:0.31997\n",
      "[6]\tvalidation_0-logloss:0.28786\tvalidation_1-logloss:0.29134\n",
      "[8]\tvalidation_0-logloss:0.27246\tvalidation_1-logloss:0.27651\n",
      "[10]\tvalidation_0-logloss:0.26397\tvalidation_1-logloss:0.26866\n",
      "[12]\tvalidation_0-logloss:0.25866\tvalidation_1-logloss:0.26397\n",
      "[14]\tvalidation_0-logloss:0.25539\tvalidation_1-logloss:0.26092\n",
      "[16]\tvalidation_0-logloss:0.25321\tvalidation_1-logloss:0.25912\n",
      "[18]\tvalidation_0-logloss:0.25170\tvalidation_1-logloss:0.25797\n",
      "[20]\tvalidation_0-logloss:0.25044\tvalidation_1-logloss:0.25720\n",
      "[22]\tvalidation_0-logloss:0.24950\tvalidation_1-logloss:0.25659\n",
      "[24]\tvalidation_0-logloss:0.24838\tvalidation_1-logloss:0.25619\n",
      "[26]\tvalidation_0-logloss:0.24781\tvalidation_1-logloss:0.25593\n",
      "[28]\tvalidation_0-logloss:0.24712\tvalidation_1-logloss:0.25566\n",
      "[30]\tvalidation_0-logloss:0.24679\tvalidation_1-logloss:0.25562\n",
      "[32]\tvalidation_0-logloss:0.24628\tvalidation_1-logloss:0.25551\n",
      "[34]\tvalidation_0-logloss:0.24544\tvalidation_1-logloss:0.25556\n",
      "[36]\tvalidation_0-logloss:0.24515\tvalidation_1-logloss:0.25550\n",
      "[38]\tvalidation_0-logloss:0.24455\tvalidation_1-logloss:0.25543\n",
      "[40]\tvalidation_0-logloss:0.24415\tvalidation_1-logloss:0.25546\n",
      "[42]\tvalidation_0-logloss:0.24371\tvalidation_1-logloss:0.25551\n",
      "[44]\tvalidation_0-logloss:0.24293\tvalidation_1-logloss:0.25545\n",
      "[46]\tvalidation_0-logloss:0.24267\tvalidation_1-logloss:0.25555\n",
      "[48]\tvalidation_0-logloss:0.24211\tvalidation_1-logloss:0.25568\n",
      "[50]\tvalidation_0-logloss:0.24153\tvalidation_1-logloss:0.25582\n",
      "[52]\tvalidation_0-logloss:0.24117\tvalidation_1-logloss:0.25589\n",
      "[54]\tvalidation_0-logloss:0.24066\tvalidation_1-logloss:0.25599\n",
      "[56]\tvalidation_0-logloss:0.24054\tvalidation_1-logloss:0.25609\n",
      "[58]\tvalidation_0-logloss:0.24034\tvalidation_1-logloss:0.25611\n",
      "[60]\tvalidation_0-logloss:0.23999\tvalidation_1-logloss:0.25614\n",
      "[62]\tvalidation_0-logloss:0.23963\tvalidation_1-logloss:0.25632\n",
      "[64]\tvalidation_0-logloss:0.23944\tvalidation_1-logloss:0.25632\n",
      "[66]\tvalidation_0-logloss:0.23925\tvalidation_1-logloss:0.25641\n",
      "Stopping. Best iteration:\n",
      "[37]\tvalidation_0-logloss:0.24490\tvalidation_1-logloss:0.25543\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.52696\tvalidation_1-logloss:0.52760\n",
      "Multiple eval metrics have been passed: 'validation_1-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-logloss hasn't improved in 30 rounds.\n",
      "[2]\tvalidation_0-logloss:0.37919\tvalidation_1-logloss:0.38082\n",
      "[4]\tvalidation_0-logloss:0.31750\tvalidation_1-logloss:0.32007\n",
      "[6]\tvalidation_0-logloss:0.28770\tvalidation_1-logloss:0.29117\n",
      "[8]\tvalidation_0-logloss:0.27236\tvalidation_1-logloss:0.27645\n",
      "[10]\tvalidation_0-logloss:0.26380\tvalidation_1-logloss:0.26852\n",
      "[12]\tvalidation_0-logloss:0.25856\tvalidation_1-logloss:0.26356\n",
      "[14]\tvalidation_0-logloss:0.25541\tvalidation_1-logloss:0.26077\n",
      "[16]\tvalidation_0-logloss:0.25334\tvalidation_1-logloss:0.25912\n",
      "[18]\tvalidation_0-logloss:0.25174\tvalidation_1-logloss:0.25794\n",
      "[20]\tvalidation_0-logloss:0.25040\tvalidation_1-logloss:0.25710\n",
      "[22]\tvalidation_0-logloss:0.24948\tvalidation_1-logloss:0.25662\n",
      "[24]\tvalidation_0-logloss:0.24872\tvalidation_1-logloss:0.25618\n",
      "[26]\tvalidation_0-logloss:0.24804\tvalidation_1-logloss:0.25595\n",
      "[28]\tvalidation_0-logloss:0.24711\tvalidation_1-logloss:0.25572\n",
      "[30]\tvalidation_0-logloss:0.24642\tvalidation_1-logloss:0.25553\n",
      "[32]\tvalidation_0-logloss:0.24605\tvalidation_1-logloss:0.25546\n",
      "[34]\tvalidation_0-logloss:0.24573\tvalidation_1-logloss:0.25545\n",
      "[36]\tvalidation_0-logloss:0.24464\tvalidation_1-logloss:0.25558\n",
      "[38]\tvalidation_0-logloss:0.24392\tvalidation_1-logloss:0.25566\n",
      "[40]\tvalidation_0-logloss:0.24365\tvalidation_1-logloss:0.25566\n",
      "[42]\tvalidation_0-logloss:0.24293\tvalidation_1-logloss:0.25568\n",
      "[44]\tvalidation_0-logloss:0.24255\tvalidation_1-logloss:0.25571\n",
      "[46]\tvalidation_0-logloss:0.24228\tvalidation_1-logloss:0.25572\n",
      "[48]\tvalidation_0-logloss:0.24143\tvalidation_1-logloss:0.25583\n",
      "[50]\tvalidation_0-logloss:0.24097\tvalidation_1-logloss:0.25585\n",
      "[52]\tvalidation_0-logloss:0.24077\tvalidation_1-logloss:0.25593\n",
      "[54]\tvalidation_0-logloss:0.24060\tvalidation_1-logloss:0.25596\n",
      "[56]\tvalidation_0-logloss:0.24034\tvalidation_1-logloss:0.25603\n",
      "[58]\tvalidation_0-logloss:0.23977\tvalidation_1-logloss:0.25616\n",
      "[60]\tvalidation_0-logloss:0.23920\tvalidation_1-logloss:0.25621\n",
      "[62]\tvalidation_0-logloss:0.23844\tvalidation_1-logloss:0.25640\n",
      "Stopping. Best iteration:\n",
      "[33]\tvalidation_0-logloss:0.24596\tvalidation_1-logloss:0.25544\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.52694\tvalidation_1-logloss:0.52765\n",
      "Multiple eval metrics have been passed: 'validation_1-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-logloss hasn't improved in 30 rounds.\n",
      "[2]\tvalidation_0-logloss:0.37926\tvalidation_1-logloss:0.38105\n",
      "[4]\tvalidation_0-logloss:0.31733\tvalidation_1-logloss:0.32007\n",
      "[6]\tvalidation_0-logloss:0.28783\tvalidation_1-logloss:0.29138\n",
      "[8]\tvalidation_0-logloss:0.27239\tvalidation_1-logloss:0.27648\n",
      "[10]\tvalidation_0-logloss:0.26373\tvalidation_1-logloss:0.26838\n",
      "[12]\tvalidation_0-logloss:0.25853\tvalidation_1-logloss:0.26349\n",
      "[14]\tvalidation_0-logloss:0.25543\tvalidation_1-logloss:0.26093\n",
      "[16]\tvalidation_0-logloss:0.25325\tvalidation_1-logloss:0.25919\n",
      "[18]\tvalidation_0-logloss:0.25127\tvalidation_1-logloss:0.25787\n",
      "[20]\tvalidation_0-logloss:0.25003\tvalidation_1-logloss:0.25701\n",
      "[22]\tvalidation_0-logloss:0.24894\tvalidation_1-logloss:0.25644\n",
      "[24]\tvalidation_0-logloss:0.24812\tvalidation_1-logloss:0.25608\n",
      "[26]\tvalidation_0-logloss:0.24735\tvalidation_1-logloss:0.25567\n",
      "[28]\tvalidation_0-logloss:0.24681\tvalidation_1-logloss:0.25551\n",
      "[30]\tvalidation_0-logloss:0.24616\tvalidation_1-logloss:0.25541\n",
      "[32]\tvalidation_0-logloss:0.24571\tvalidation_1-logloss:0.25536\n",
      "[34]\tvalidation_0-logloss:0.24513\tvalidation_1-logloss:0.25535\n",
      "[36]\tvalidation_0-logloss:0.24481\tvalidation_1-logloss:0.25543\n",
      "[38]\tvalidation_0-logloss:0.24425\tvalidation_1-logloss:0.25548\n",
      "[40]\tvalidation_0-logloss:0.24400\tvalidation_1-logloss:0.25546\n",
      "[42]\tvalidation_0-logloss:0.24364\tvalidation_1-logloss:0.25550\n",
      "[44]\tvalidation_0-logloss:0.24334\tvalidation_1-logloss:0.25547\n",
      "[46]\tvalidation_0-logloss:0.24220\tvalidation_1-logloss:0.25582\n",
      "[48]\tvalidation_0-logloss:0.24201\tvalidation_1-logloss:0.25586\n",
      "[50]\tvalidation_0-logloss:0.24169\tvalidation_1-logloss:0.25587\n",
      "[52]\tvalidation_0-logloss:0.24147\tvalidation_1-logloss:0.25591\n",
      "[54]\tvalidation_0-logloss:0.24104\tvalidation_1-logloss:0.25602\n",
      "[56]\tvalidation_0-logloss:0.24025\tvalidation_1-logloss:0.25607\n",
      "[58]\tvalidation_0-logloss:0.23973\tvalidation_1-logloss:0.25617\n",
      "[60]\tvalidation_0-logloss:0.23910\tvalidation_1-logloss:0.25624\n",
      "[62]\tvalidation_0-logloss:0.23859\tvalidation_1-logloss:0.25642\n",
      "[64]\tvalidation_0-logloss:0.23833\tvalidation_1-logloss:0.25652\n",
      "Stopping. Best iteration:\n",
      "[34]\tvalidation_0-logloss:0.24513\tvalidation_1-logloss:0.25535\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.52680\tvalidation_1-logloss:0.52749\n",
      "Multiple eval metrics have been passed: 'validation_1-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-logloss hasn't improved in 30 rounds.\n",
      "[2]\tvalidation_0-logloss:0.37914\tvalidation_1-logloss:0.38109\n",
      "[4]\tvalidation_0-logloss:0.31738\tvalidation_1-logloss:0.32038\n",
      "[6]\tvalidation_0-logloss:0.28774\tvalidation_1-logloss:0.29142\n",
      "[8]\tvalidation_0-logloss:0.27240\tvalidation_1-logloss:0.27676\n",
      "[10]\tvalidation_0-logloss:0.26373\tvalidation_1-logloss:0.26854\n",
      "[12]\tvalidation_0-logloss:0.25856\tvalidation_1-logloss:0.26372\n",
      "[14]\tvalidation_0-logloss:0.25534\tvalidation_1-logloss:0.26101\n",
      "[16]\tvalidation_0-logloss:0.25315\tvalidation_1-logloss:0.25939\n",
      "[18]\tvalidation_0-logloss:0.25155\tvalidation_1-logloss:0.25807\n",
      "[20]\tvalidation_0-logloss:0.25039\tvalidation_1-logloss:0.25726\n",
      "[22]\tvalidation_0-logloss:0.24940\tvalidation_1-logloss:0.25666\n",
      "[24]\tvalidation_0-logloss:0.24832\tvalidation_1-logloss:0.25623\n",
      "[26]\tvalidation_0-logloss:0.24781\tvalidation_1-logloss:0.25596\n",
      "[28]\tvalidation_0-logloss:0.24717\tvalidation_1-logloss:0.25575\n",
      "[30]\tvalidation_0-logloss:0.24681\tvalidation_1-logloss:0.25564\n",
      "[32]\tvalidation_0-logloss:0.24580\tvalidation_1-logloss:0.25561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34]\tvalidation_0-logloss:0.24538\tvalidation_1-logloss:0.25562\n",
      "[36]\tvalidation_0-logloss:0.24512\tvalidation_1-logloss:0.25553\n",
      "[38]\tvalidation_0-logloss:0.24444\tvalidation_1-logloss:0.25550\n",
      "[40]\tvalidation_0-logloss:0.24363\tvalidation_1-logloss:0.25564\n",
      "[42]\tvalidation_0-logloss:0.24328\tvalidation_1-logloss:0.25560\n",
      "[44]\tvalidation_0-logloss:0.24280\tvalidation_1-logloss:0.25564\n",
      "[46]\tvalidation_0-logloss:0.24254\tvalidation_1-logloss:0.25567\n",
      "[48]\tvalidation_0-logloss:0.24177\tvalidation_1-logloss:0.25575\n",
      "[50]\tvalidation_0-logloss:0.24143\tvalidation_1-logloss:0.25589\n",
      "[52]\tvalidation_0-logloss:0.24127\tvalidation_1-logloss:0.25592\n",
      "[54]\tvalidation_0-logloss:0.24103\tvalidation_1-logloss:0.25597\n",
      "[56]\tvalidation_0-logloss:0.24041\tvalidation_1-logloss:0.25604\n",
      "[58]\tvalidation_0-logloss:0.23986\tvalidation_1-logloss:0.25615\n",
      "[60]\tvalidation_0-logloss:0.23923\tvalidation_1-logloss:0.25630\n",
      "[62]\tvalidation_0-logloss:0.23885\tvalidation_1-logloss:0.25635\n",
      "[64]\tvalidation_0-logloss:0.23844\tvalidation_1-logloss:0.25641\n",
      "[66]\tvalidation_0-logloss:0.23786\tvalidation_1-logloss:0.25655\n",
      "Stopping. Best iteration:\n",
      "[37]\tvalidation_0-logloss:0.24462\tvalidation_1-logloss:0.25548\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.52686\tvalidation_1-logloss:0.52755\n",
      "Multiple eval metrics have been passed: 'validation_1-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-logloss hasn't improved in 30 rounds.\n",
      "[2]\tvalidation_0-logloss:0.37904\tvalidation_1-logloss:0.38077\n",
      "[4]\tvalidation_0-logloss:0.31721\tvalidation_1-logloss:0.32008\n",
      "[6]\tvalidation_0-logloss:0.28751\tvalidation_1-logloss:0.29129\n",
      "[8]\tvalidation_0-logloss:0.27211\tvalidation_1-logloss:0.27654\n",
      "[10]\tvalidation_0-logloss:0.26359\tvalidation_1-logloss:0.26852\n",
      "[12]\tvalidation_0-logloss:0.25841\tvalidation_1-logloss:0.26372\n",
      "[14]\tvalidation_0-logloss:0.25511\tvalidation_1-logloss:0.26098\n",
      "[16]\tvalidation_0-logloss:0.25305\tvalidation_1-logloss:0.25937\n",
      "[18]\tvalidation_0-logloss:0.25139\tvalidation_1-logloss:0.25805\n",
      "[20]\tvalidation_0-logloss:0.25011\tvalidation_1-logloss:0.25731\n",
      "[22]\tvalidation_0-logloss:0.24892\tvalidation_1-logloss:0.25671\n",
      "[24]\tvalidation_0-logloss:0.24807\tvalidation_1-logloss:0.25631\n",
      "[26]\tvalidation_0-logloss:0.24756\tvalidation_1-logloss:0.25615\n",
      "[28]\tvalidation_0-logloss:0.24671\tvalidation_1-logloss:0.25595\n",
      "[30]\tvalidation_0-logloss:0.24599\tvalidation_1-logloss:0.25589\n",
      "[32]\tvalidation_0-logloss:0.24561\tvalidation_1-logloss:0.25581\n",
      "[34]\tvalidation_0-logloss:0.24469\tvalidation_1-logloss:0.25571\n",
      "[36]\tvalidation_0-logloss:0.24416\tvalidation_1-logloss:0.25573\n",
      "[38]\tvalidation_0-logloss:0.24390\tvalidation_1-logloss:0.25574\n",
      "[40]\tvalidation_0-logloss:0.24362\tvalidation_1-logloss:0.25575\n",
      "[42]\tvalidation_0-logloss:0.24334\tvalidation_1-logloss:0.25578\n",
      "[44]\tvalidation_0-logloss:0.24309\tvalidation_1-logloss:0.25585\n",
      "[46]\tvalidation_0-logloss:0.24243\tvalidation_1-logloss:0.25586\n",
      "[48]\tvalidation_0-logloss:0.24209\tvalidation_1-logloss:0.25594\n",
      "[50]\tvalidation_0-logloss:0.24181\tvalidation_1-logloss:0.25601\n",
      "[52]\tvalidation_0-logloss:0.24152\tvalidation_1-logloss:0.25599\n",
      "[54]\tvalidation_0-logloss:0.24083\tvalidation_1-logloss:0.25607\n",
      "[56]\tvalidation_0-logloss:0.24028\tvalidation_1-logloss:0.25616\n",
      "[58]\tvalidation_0-logloss:0.24011\tvalidation_1-logloss:0.25624\n",
      "[60]\tvalidation_0-logloss:0.23975\tvalidation_1-logloss:0.25629\n",
      "[62]\tvalidation_0-logloss:0.23962\tvalidation_1-logloss:0.25630\n",
      "[64]\tvalidation_0-logloss:0.23924\tvalidation_1-logloss:0.25637\n",
      "Stopping. Best iteration:\n",
      "[35]\tvalidation_0-logloss:0.24441\tvalidation_1-logloss:0.25570\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.52499\tvalidation_1-logloss:0.52582\n",
      "Multiple eval metrics have been passed: 'validation_1-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-logloss hasn't improved in 30 rounds.\n",
      "[2]\tvalidation_0-logloss:0.37545\tvalidation_1-logloss:0.37786\n",
      "[4]\tvalidation_0-logloss:0.31266\tvalidation_1-logloss:0.31677\n",
      "[6]\tvalidation_0-logloss:0.28236\tvalidation_1-logloss:0.28784\n",
      "[8]\tvalidation_0-logloss:0.26675\tvalidation_1-logloss:0.27339\n",
      "[10]\tvalidation_0-logloss:0.25808\tvalidation_1-logloss:0.26594\n",
      "[12]\tvalidation_0-logloss:0.25283\tvalidation_1-logloss:0.26157\n",
      "[14]\tvalidation_0-logloss:0.24977\tvalidation_1-logloss:0.25918\n",
      "[16]\tvalidation_0-logloss:0.24772\tvalidation_1-logloss:0.25783\n",
      "[18]\tvalidation_0-logloss:0.24639\tvalidation_1-logloss:0.25711\n",
      "[20]\tvalidation_0-logloss:0.24551\tvalidation_1-logloss:0.25664\n",
      "[22]\tvalidation_0-logloss:0.24456\tvalidation_1-logloss:0.25644\n",
      "[24]\tvalidation_0-logloss:0.24380\tvalidation_1-logloss:0.25633\n",
      "[26]\tvalidation_0-logloss:0.24236\tvalidation_1-logloss:0.25626\n",
      "[28]\tvalidation_0-logloss:0.24165\tvalidation_1-logloss:0.25628\n",
      "[30]\tvalidation_0-logloss:0.24036\tvalidation_1-logloss:0.25626\n",
      "[32]\tvalidation_0-logloss:0.24009\tvalidation_1-logloss:0.25624\n",
      "[34]\tvalidation_0-logloss:0.23968\tvalidation_1-logloss:0.25627\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-114ec1b4e52b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0meval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"logloss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    822\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1367\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1368\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier()\n",
    "\n",
    "params = {'n_estimators': [300],\n",
    "          'max_depth': [8, 10, 12, 14, 16]}\n",
    "\n",
    "eval_set = [(x_train, y_train), (x_test1, y_test1)]\n",
    "clf = GridSearchCV(xg, params)\n",
    "clf.fit(x_train, y_train, eval_metric=\"logloss\", eval_set=eval_set, verbose=2, early_stopping_rounds = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(verbose=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=400, \n",
    "                            max_depth=12,\n",
    "                            max_features=\"auto\",\n",
    "                            min_samples_split=2,\n",
    "                            min_samples_leaf=1,\n",
    "                            verbose=2)\n",
    "\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Feature Importance Score')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_imp = pd.Series(rf.feature_importances_).sort_values(ascending=False)\n",
    "plt.figure(figsize=(12,8))\n",
    "feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:20:32] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { boosting_type, max_features } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-logloss:1.02950\tvalidation_1-logloss:1.03031\n",
      "Multiple eval metrics have been passed: 'validation_1-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-logloss hasn't improved in 200 rounds.\n",
      "[2]\tvalidation_0-logloss:0.99987\tvalidation_1-logloss:1.00048\n",
      "[4]\tvalidation_0-logloss:0.97206\tvalidation_1-logloss:0.97240\n",
      "[6]\tvalidation_0-logloss:0.94576\tvalidation_1-logloss:0.94597\n",
      "[8]\tvalidation_0-logloss:0.92066\tvalidation_1-logloss:0.92104\n",
      "[10]\tvalidation_0-logloss:0.89721\tvalidation_1-logloss:0.89741\n",
      "[12]\tvalidation_0-logloss:0.87490\tvalidation_1-logloss:0.87507\n",
      "[14]\tvalidation_0-logloss:0.85351\tvalidation_1-logloss:0.85385\n",
      "[16]\tvalidation_0-logloss:0.83351\tvalidation_1-logloss:0.83366\n",
      "[18]\tvalidation_0-logloss:0.81421\tvalidation_1-logloss:0.81445\n",
      "[20]\tvalidation_0-logloss:0.79607\tvalidation_1-logloss:0.79612\n",
      "[22]\tvalidation_0-logloss:0.77860\tvalidation_1-logloss:0.77864\n",
      "[24]\tvalidation_0-logloss:0.76186\tvalidation_1-logloss:0.76196\n",
      "[26]\tvalidation_0-logloss:0.74598\tvalidation_1-logloss:0.74598\n",
      "[28]\tvalidation_0-logloss:0.73068\tvalidation_1-logloss:0.73069\n",
      "[30]\tvalidation_0-logloss:0.71609\tvalidation_1-logloss:0.71608\n",
      "[32]\tvalidation_0-logloss:0.70207\tvalidation_1-logloss:0.70199\n",
      "[34]\tvalidation_0-logloss:0.68859\tvalidation_1-logloss:0.68852\n",
      "[36]\tvalidation_0-logloss:0.67564\tvalidation_1-logloss:0.67559\n",
      "[38]\tvalidation_0-logloss:0.66318\tvalidation_1-logloss:0.66310\n",
      "[40]\tvalidation_0-logloss:0.65118\tvalidation_1-logloss:0.65114\n",
      "[42]\tvalidation_0-logloss:0.63972\tvalidation_1-logloss:0.63960\n",
      "[44]\tvalidation_0-logloss:0.62859\tvalidation_1-logloss:0.62852\n",
      "[46]\tvalidation_0-logloss:0.61793\tvalidation_1-logloss:0.61783\n",
      "[48]\tvalidation_0-logloss:0.60759\tvalidation_1-logloss:0.60752\n",
      "[50]\tvalidation_0-logloss:0.59769\tvalidation_1-logloss:0.59759\n",
      "[52]\tvalidation_0-logloss:0.58817\tvalidation_1-logloss:0.58796\n",
      "[54]\tvalidation_0-logloss:0.57884\tvalidation_1-logloss:0.57871\n",
      "[56]\tvalidation_0-logloss:0.56989\tvalidation_1-logloss:0.56978\n",
      "[58]\tvalidation_0-logloss:0.56121\tvalidation_1-logloss:0.56112\n",
      "[60]\tvalidation_0-logloss:0.55289\tvalidation_1-logloss:0.55277\n",
      "[62]\tvalidation_0-logloss:0.54479\tvalidation_1-logloss:0.54470\n",
      "[64]\tvalidation_0-logloss:0.53695\tvalidation_1-logloss:0.53685\n",
      "[66]\tvalidation_0-logloss:0.52938\tvalidation_1-logloss:0.52929\n",
      "[68]\tvalidation_0-logloss:0.52195\tvalidation_1-logloss:0.52198\n",
      "[70]\tvalidation_0-logloss:0.51493\tvalidation_1-logloss:0.51487\n",
      "[72]\tvalidation_0-logloss:0.50797\tvalidation_1-logloss:0.50799\n",
      "[74]\tvalidation_0-logloss:0.50126\tvalidation_1-logloss:0.50131\n",
      "[76]\tvalidation_0-logloss:0.49476\tvalidation_1-logloss:0.49486\n",
      "[78]\tvalidation_0-logloss:0.48860\tvalidation_1-logloss:0.48858\n",
      "[80]\tvalidation_0-logloss:0.48247\tvalidation_1-logloss:0.48251\n",
      "[82]\tvalidation_0-logloss:0.47653\tvalidation_1-logloss:0.47660\n",
      "[84]\tvalidation_0-logloss:0.47082\tvalidation_1-logloss:0.47088\n",
      "[86]\tvalidation_0-logloss:0.46530\tvalidation_1-logloss:0.46530\n",
      "[88]\tvalidation_0-logloss:0.45977\tvalidation_1-logloss:0.45994\n",
      "[90]\tvalidation_0-logloss:0.45453\tvalidation_1-logloss:0.45470\n",
      "[92]\tvalidation_0-logloss:0.44944\tvalidation_1-logloss:0.44963\n",
      "[94]\tvalidation_0-logloss:0.44458\tvalidation_1-logloss:0.44467\n",
      "[96]\tvalidation_0-logloss:0.43975\tvalidation_1-logloss:0.43990\n",
      "[98]\tvalidation_0-logloss:0.43504\tvalidation_1-logloss:0.43524\n",
      "[100]\tvalidation_0-logloss:0.43052\tvalidation_1-logloss:0.43071\n",
      "[102]\tvalidation_0-logloss:0.42606\tvalidation_1-logloss:0.42632\n",
      "[104]\tvalidation_0-logloss:0.42182\tvalidation_1-logloss:0.42205\n",
      "[106]\tvalidation_0-logloss:0.41766\tvalidation_1-logloss:0.41789\n",
      "[108]\tvalidation_0-logloss:0.41352\tvalidation_1-logloss:0.41384\n",
      "[110]\tvalidation_0-logloss:0.40953\tvalidation_1-logloss:0.40991\n",
      "[112]\tvalidation_0-logloss:0.40567\tvalidation_1-logloss:0.40610\n",
      "[114]\tvalidation_0-logloss:0.40193\tvalidation_1-logloss:0.40236\n",
      "[116]\tvalidation_0-logloss:0.39832\tvalidation_1-logloss:0.39875\n",
      "[118]\tvalidation_0-logloss:0.39478\tvalidation_1-logloss:0.39522\n",
      "[120]\tvalidation_0-logloss:0.39129\tvalidation_1-logloss:0.39181\n",
      "[122]\tvalidation_0-logloss:0.38792\tvalidation_1-logloss:0.38845\n",
      "[124]\tvalidation_0-logloss:0.38471\tvalidation_1-logloss:0.38520\n",
      "[126]\tvalidation_0-logloss:0.38141\tvalidation_1-logloss:0.38203\n",
      "[128]\tvalidation_0-logloss:0.37837\tvalidation_1-logloss:0.37895\n",
      "[130]\tvalidation_0-logloss:0.37524\tvalidation_1-logloss:0.37595\n",
      "[132]\tvalidation_0-logloss:0.37229\tvalidation_1-logloss:0.37300\n",
      "[134]\tvalidation_0-logloss:0.36946\tvalidation_1-logloss:0.37016\n",
      "[136]\tvalidation_0-logloss:0.36664\tvalidation_1-logloss:0.36738\n",
      "[138]\tvalidation_0-logloss:0.36386\tvalidation_1-logloss:0.36468\n",
      "[140]\tvalidation_0-logloss:0.36118\tvalidation_1-logloss:0.36204\n",
      "[142]\tvalidation_0-logloss:0.35859\tvalidation_1-logloss:0.35948\n",
      "[144]\tvalidation_0-logloss:0.35602\tvalidation_1-logloss:0.35697\n",
      "[146]\tvalidation_0-logloss:0.35353\tvalidation_1-logloss:0.35454\n",
      "[148]\tvalidation_0-logloss:0.35113\tvalidation_1-logloss:0.35214\n",
      "[150]\tvalidation_0-logloss:0.34876\tvalidation_1-logloss:0.34981\n",
      "[152]\tvalidation_0-logloss:0.34646\tvalidation_1-logloss:0.34753\n",
      "[154]\tvalidation_0-logloss:0.34421\tvalidation_1-logloss:0.34532\n",
      "[156]\tvalidation_0-logloss:0.34206\tvalidation_1-logloss:0.34316\n",
      "[158]\tvalidation_0-logloss:0.33986\tvalidation_1-logloss:0.34105\n",
      "[160]\tvalidation_0-logloss:0.33779\tvalidation_1-logloss:0.33900\n",
      "[162]\tvalidation_0-logloss:0.33578\tvalidation_1-logloss:0.33701\n",
      "[164]\tvalidation_0-logloss:0.33377\tvalidation_1-logloss:0.33505\n",
      "[166]\tvalidation_0-logloss:0.33190\tvalidation_1-logloss:0.33314\n",
      "[168]\tvalidation_0-logloss:0.32996\tvalidation_1-logloss:0.33129\n",
      "[170]\tvalidation_0-logloss:0.32816\tvalidation_1-logloss:0.32948\n",
      "[172]\tvalidation_0-logloss:0.32629\tvalidation_1-logloss:0.32773\n",
      "[174]\tvalidation_0-logloss:0.32460\tvalidation_1-logloss:0.32601\n",
      "[176]\tvalidation_0-logloss:0.32282\tvalidation_1-logloss:0.32432\n",
      "[178]\tvalidation_0-logloss:0.32116\tvalidation_1-logloss:0.32269\n",
      "[180]\tvalidation_0-logloss:0.31954\tvalidation_1-logloss:0.32109\n",
      "[182]\tvalidation_0-logloss:0.31793\tvalidation_1-logloss:0.31952\n",
      "[184]\tvalidation_0-logloss:0.31634\tvalidation_1-logloss:0.31801\n",
      "[186]\tvalidation_0-logloss:0.31483\tvalidation_1-logloss:0.31652\n",
      "[188]\tvalidation_0-logloss:0.31333\tvalidation_1-logloss:0.31505\n",
      "[190]\tvalidation_0-logloss:0.31183\tvalidation_1-logloss:0.31363\n",
      "[192]\tvalidation_0-logloss:0.31036\tvalidation_1-logloss:0.31225\n",
      "[194]\tvalidation_0-logloss:0.30900\tvalidation_1-logloss:0.31090\n",
      "[196]\tvalidation_0-logloss:0.30767\tvalidation_1-logloss:0.30958\n",
      "[198]\tvalidation_0-logloss:0.30635\tvalidation_1-logloss:0.30830\n",
      "[200]\tvalidation_0-logloss:0.30504\tvalidation_1-logloss:0.30704\n",
      "[202]\tvalidation_0-logloss:0.30373\tvalidation_1-logloss:0.30581\n",
      "[204]\tvalidation_0-logloss:0.30250\tvalidation_1-logloss:0.30462\n",
      "[206]\tvalidation_0-logloss:0.30127\tvalidation_1-logloss:0.30345\n",
      "[208]\tvalidation_0-logloss:0.30008\tvalidation_1-logloss:0.30230\n",
      "[210]\tvalidation_0-logloss:0.29896\tvalidation_1-logloss:0.30118\n",
      "[212]\tvalidation_0-logloss:0.29780\tvalidation_1-logloss:0.30009\n",
      "[214]\tvalidation_0-logloss:0.29667\tvalidation_1-logloss:0.29902\n",
      "[216]\tvalidation_0-logloss:0.29556\tvalidation_1-logloss:0.29798\n",
      "[218]\tvalidation_0-logloss:0.29448\tvalidation_1-logloss:0.29696\n",
      "[220]\tvalidation_0-logloss:0.29348\tvalidation_1-logloss:0.29596\n",
      "[222]\tvalidation_0-logloss:0.29243\tvalidation_1-logloss:0.29500\n",
      "[224]\tvalidation_0-logloss:0.29148\tvalidation_1-logloss:0.29405\n",
      "[226]\tvalidation_0-logloss:0.29051\tvalidation_1-logloss:0.29312\n",
      "[228]\tvalidation_0-logloss:0.28951\tvalidation_1-logloss:0.29220\n",
      "[230]\tvalidation_0-logloss:0.28862\tvalidation_1-logloss:0.29131\n",
      "[232]\tvalidation_0-logloss:0.28772\tvalidation_1-logloss:0.29045\n",
      "[234]\tvalidation_0-logloss:0.28684\tvalidation_1-logloss:0.28961\n",
      "[236]\tvalidation_0-logloss:0.28589\tvalidation_1-logloss:0.28877\n",
      "[238]\tvalidation_0-logloss:0.28506\tvalidation_1-logloss:0.28796\n",
      "[240]\tvalidation_0-logloss:0.28424\tvalidation_1-logloss:0.28718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[242]\tvalidation_0-logloss:0.28343\tvalidation_1-logloss:0.28641\n",
      "[244]\tvalidation_0-logloss:0.28263\tvalidation_1-logloss:0.28565\n",
      "[246]\tvalidation_0-logloss:0.28185\tvalidation_1-logloss:0.28490\n",
      "[248]\tvalidation_0-logloss:0.28107\tvalidation_1-logloss:0.28418\n",
      "[250]\tvalidation_0-logloss:0.28033\tvalidation_1-logloss:0.28348\n",
      "[252]\tvalidation_0-logloss:0.27963\tvalidation_1-logloss:0.28279\n",
      "[254]\tvalidation_0-logloss:0.27883\tvalidation_1-logloss:0.28213\n",
      "[256]\tvalidation_0-logloss:0.27818\tvalidation_1-logloss:0.28148\n",
      "[258]\tvalidation_0-logloss:0.27747\tvalidation_1-logloss:0.28083\n",
      "[260]\tvalidation_0-logloss:0.27680\tvalidation_1-logloss:0.28021\n",
      "[262]\tvalidation_0-logloss:0.27618\tvalidation_1-logloss:0.27959\n",
      "[264]\tvalidation_0-logloss:0.27552\tvalidation_1-logloss:0.27900\n",
      "[266]\tvalidation_0-logloss:0.27491\tvalidation_1-logloss:0.27841\n",
      "[268]\tvalidation_0-logloss:0.27426\tvalidation_1-logloss:0.27784\n",
      "[270]\tvalidation_0-logloss:0.27369\tvalidation_1-logloss:0.27728\n",
      "[272]\tvalidation_0-logloss:0.27308\tvalidation_1-logloss:0.27673\n",
      "[274]\tvalidation_0-logloss:0.27252\tvalidation_1-logloss:0.27619\n",
      "[276]\tvalidation_0-logloss:0.27193\tvalidation_1-logloss:0.27566\n",
      "[278]\tvalidation_0-logloss:0.27137\tvalidation_1-logloss:0.27516\n",
      "[280]\tvalidation_0-logloss:0.27080\tvalidation_1-logloss:0.27465\n",
      "[282]\tvalidation_0-logloss:0.27028\tvalidation_1-logloss:0.27415\n",
      "[284]\tvalidation_0-logloss:0.26976\tvalidation_1-logloss:0.27369\n",
      "[286]\tvalidation_0-logloss:0.26921\tvalidation_1-logloss:0.27321\n",
      "[288]\tvalidation_0-logloss:0.26872\tvalidation_1-logloss:0.27276\n",
      "[290]\tvalidation_0-logloss:0.26823\tvalidation_1-logloss:0.27231\n",
      "[292]\tvalidation_0-logloss:0.26774\tvalidation_1-logloss:0.27187\n",
      "[294]\tvalidation_0-logloss:0.26724\tvalidation_1-logloss:0.27144\n",
      "[296]\tvalidation_0-logloss:0.26675\tvalidation_1-logloss:0.27102\n",
      "[298]\tvalidation_0-logloss:0.26634\tvalidation_1-logloss:0.27060\n",
      "[300]\tvalidation_0-logloss:0.26585\tvalidation_1-logloss:0.27020\n",
      "[302]\tvalidation_0-logloss:0.26540\tvalidation_1-logloss:0.26980\n",
      "[304]\tvalidation_0-logloss:0.26496\tvalidation_1-logloss:0.26942\n",
      "[306]\tvalidation_0-logloss:0.26454\tvalidation_1-logloss:0.26904\n",
      "[308]\tvalidation_0-logloss:0.26414\tvalidation_1-logloss:0.26867\n",
      "[310]\tvalidation_0-logloss:0.26371\tvalidation_1-logloss:0.26831\n",
      "[312]\tvalidation_0-logloss:0.26329\tvalidation_1-logloss:0.26797\n",
      "[314]\tvalidation_0-logloss:0.26291\tvalidation_1-logloss:0.26762\n",
      "[316]\tvalidation_0-logloss:0.26251\tvalidation_1-logloss:0.26729\n",
      "[318]\tvalidation_0-logloss:0.26214\tvalidation_1-logloss:0.26695\n",
      "[320]\tvalidation_0-logloss:0.26176\tvalidation_1-logloss:0.26664\n",
      "[322]\tvalidation_0-logloss:0.26142\tvalidation_1-logloss:0.26631\n",
      "[324]\tvalidation_0-logloss:0.26100\tvalidation_1-logloss:0.26601\n",
      "[326]\tvalidation_0-logloss:0.26065\tvalidation_1-logloss:0.26571\n",
      "[328]\tvalidation_0-logloss:0.26029\tvalidation_1-logloss:0.26540\n",
      "[330]\tvalidation_0-logloss:0.25994\tvalidation_1-logloss:0.26511\n",
      "[332]\tvalidation_0-logloss:0.25961\tvalidation_1-logloss:0.26483\n",
      "[334]\tvalidation_0-logloss:0.25926\tvalidation_1-logloss:0.26456\n",
      "[336]\tvalidation_0-logloss:0.25896\tvalidation_1-logloss:0.26429\n",
      "[338]\tvalidation_0-logloss:0.25864\tvalidation_1-logloss:0.26402\n",
      "[340]\tvalidation_0-logloss:0.25832\tvalidation_1-logloss:0.26377\n",
      "[342]\tvalidation_0-logloss:0.25802\tvalidation_1-logloss:0.26351\n",
      "[344]\tvalidation_0-logloss:0.25773\tvalidation_1-logloss:0.26327\n",
      "[346]\tvalidation_0-logloss:0.25743\tvalidation_1-logloss:0.26301\n",
      "[348]\tvalidation_0-logloss:0.25712\tvalidation_1-logloss:0.26278\n",
      "[350]\tvalidation_0-logloss:0.25683\tvalidation_1-logloss:0.26254\n",
      "[352]\tvalidation_0-logloss:0.25655\tvalidation_1-logloss:0.26231\n",
      "[354]\tvalidation_0-logloss:0.25631\tvalidation_1-logloss:0.26209\n",
      "[356]\tvalidation_0-logloss:0.25600\tvalidation_1-logloss:0.26187\n",
      "[358]\tvalidation_0-logloss:0.25576\tvalidation_1-logloss:0.26165\n",
      "[360]\tvalidation_0-logloss:0.25550\tvalidation_1-logloss:0.26144\n",
      "[362]\tvalidation_0-logloss:0.25525\tvalidation_1-logloss:0.26123\n",
      "[364]\tvalidation_0-logloss:0.25501\tvalidation_1-logloss:0.26104\n",
      "[366]\tvalidation_0-logloss:0.25473\tvalidation_1-logloss:0.26085\n",
      "[368]\tvalidation_0-logloss:0.25450\tvalidation_1-logloss:0.26066\n",
      "[370]\tvalidation_0-logloss:0.25425\tvalidation_1-logloss:0.26048\n",
      "[372]\tvalidation_0-logloss:0.25400\tvalidation_1-logloss:0.26029\n",
      "[374]\tvalidation_0-logloss:0.25379\tvalidation_1-logloss:0.26012\n",
      "[376]\tvalidation_0-logloss:0.25355\tvalidation_1-logloss:0.25995\n",
      "[378]\tvalidation_0-logloss:0.25333\tvalidation_1-logloss:0.25978\n",
      "[380]\tvalidation_0-logloss:0.25313\tvalidation_1-logloss:0.25962\n",
      "[382]\tvalidation_0-logloss:0.25291\tvalidation_1-logloss:0.25945\n",
      "[384]\tvalidation_0-logloss:0.25268\tvalidation_1-logloss:0.25928\n",
      "[386]\tvalidation_0-logloss:0.25249\tvalidation_1-logloss:0.25913\n",
      "[388]\tvalidation_0-logloss:0.25227\tvalidation_1-logloss:0.25898\n",
      "[390]\tvalidation_0-logloss:0.25205\tvalidation_1-logloss:0.25881\n",
      "[392]\tvalidation_0-logloss:0.25184\tvalidation_1-logloss:0.25865\n",
      "[394]\tvalidation_0-logloss:0.25167\tvalidation_1-logloss:0.25850\n",
      "[396]\tvalidation_0-logloss:0.25144\tvalidation_1-logloss:0.25837\n",
      "[398]\tvalidation_0-logloss:0.25128\tvalidation_1-logloss:0.25822\n",
      "[400]\tvalidation_0-logloss:0.25112\tvalidation_1-logloss:0.25809\n",
      "[402]\tvalidation_0-logloss:0.25092\tvalidation_1-logloss:0.25796\n",
      "[404]\tvalidation_0-logloss:0.25075\tvalidation_1-logloss:0.25782\n",
      "[406]\tvalidation_0-logloss:0.25058\tvalidation_1-logloss:0.25769\n",
      "[408]\tvalidation_0-logloss:0.25043\tvalidation_1-logloss:0.25756\n",
      "[410]\tvalidation_0-logloss:0.25025\tvalidation_1-logloss:0.25744\n",
      "[412]\tvalidation_0-logloss:0.25006\tvalidation_1-logloss:0.25731\n",
      "[414]\tvalidation_0-logloss:0.24990\tvalidation_1-logloss:0.25719\n",
      "[416]\tvalidation_0-logloss:0.24975\tvalidation_1-logloss:0.25707\n",
      "[418]\tvalidation_0-logloss:0.24958\tvalidation_1-logloss:0.25695\n",
      "[420]\tvalidation_0-logloss:0.24941\tvalidation_1-logloss:0.25683\n",
      "[422]\tvalidation_0-logloss:0.24927\tvalidation_1-logloss:0.25671\n",
      "[424]\tvalidation_0-logloss:0.24913\tvalidation_1-logloss:0.25659\n",
      "[426]\tvalidation_0-logloss:0.24899\tvalidation_1-logloss:0.25648\n",
      "[428]\tvalidation_0-logloss:0.24880\tvalidation_1-logloss:0.25637\n",
      "[430]\tvalidation_0-logloss:0.24865\tvalidation_1-logloss:0.25627\n",
      "[432]\tvalidation_0-logloss:0.24852\tvalidation_1-logloss:0.25616\n",
      "[434]\tvalidation_0-logloss:0.24837\tvalidation_1-logloss:0.25605\n",
      "[436]\tvalidation_0-logloss:0.24824\tvalidation_1-logloss:0.25595\n",
      "[438]\tvalidation_0-logloss:0.24805\tvalidation_1-logloss:0.25585\n",
      "[440]\tvalidation_0-logloss:0.24794\tvalidation_1-logloss:0.25576\n",
      "[442]\tvalidation_0-logloss:0.24778\tvalidation_1-logloss:0.25566\n",
      "[444]\tvalidation_0-logloss:0.24765\tvalidation_1-logloss:0.25556\n",
      "[446]\tvalidation_0-logloss:0.24752\tvalidation_1-logloss:0.25548\n",
      "[448]\tvalidation_0-logloss:0.24737\tvalidation_1-logloss:0.25538\n",
      "[450]\tvalidation_0-logloss:0.24721\tvalidation_1-logloss:0.25531\n",
      "[452]\tvalidation_0-logloss:0.24709\tvalidation_1-logloss:0.25521\n",
      "[454]\tvalidation_0-logloss:0.24697\tvalidation_1-logloss:0.25513\n",
      "[456]\tvalidation_0-logloss:0.24683\tvalidation_1-logloss:0.25506\n",
      "[458]\tvalidation_0-logloss:0.24671\tvalidation_1-logloss:0.25497\n",
      "[460]\tvalidation_0-logloss:0.24658\tvalidation_1-logloss:0.25489\n",
      "[462]\tvalidation_0-logloss:0.24644\tvalidation_1-logloss:0.25482\n",
      "[464]\tvalidation_0-logloss:0.24634\tvalidation_1-logloss:0.25474\n",
      "[466]\tvalidation_0-logloss:0.24622\tvalidation_1-logloss:0.25467\n",
      "[468]\tvalidation_0-logloss:0.24609\tvalidation_1-logloss:0.25459\n",
      "[470]\tvalidation_0-logloss:0.24599\tvalidation_1-logloss:0.25453\n",
      "[472]\tvalidation_0-logloss:0.24588\tvalidation_1-logloss:0.25446\n",
      "[474]\tvalidation_0-logloss:0.24576\tvalidation_1-logloss:0.25438\n",
      "[476]\tvalidation_0-logloss:0.24565\tvalidation_1-logloss:0.25431\n",
      "[478]\tvalidation_0-logloss:0.24553\tvalidation_1-logloss:0.25425\n",
      "[480]\tvalidation_0-logloss:0.24543\tvalidation_1-logloss:0.25418\n",
      "[482]\tvalidation_0-logloss:0.24534\tvalidation_1-logloss:0.25412\n",
      "[484]\tvalidation_0-logloss:0.24523\tvalidation_1-logloss:0.25405\n",
      "[486]\tvalidation_0-logloss:0.24512\tvalidation_1-logloss:0.25400\n",
      "[488]\tvalidation_0-logloss:0.24503\tvalidation_1-logloss:0.25393\n",
      "[490]\tvalidation_0-logloss:0.24496\tvalidation_1-logloss:0.25387\n",
      "[492]\tvalidation_0-logloss:0.24487\tvalidation_1-logloss:0.25382\n",
      "[494]\tvalidation_0-logloss:0.24480\tvalidation_1-logloss:0.25376\n",
      "[496]\tvalidation_0-logloss:0.24469\tvalidation_1-logloss:0.25371\n",
      "[498]\tvalidation_0-logloss:0.24463\tvalidation_1-logloss:0.25365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalidation_0-logloss:0.24455\tvalidation_1-logloss:0.25359\n",
      "[502]\tvalidation_0-logloss:0.24449\tvalidation_1-logloss:0.25353\n",
      "[504]\tvalidation_0-logloss:0.24441\tvalidation_1-logloss:0.25349\n",
      "[506]\tvalidation_0-logloss:0.24432\tvalidation_1-logloss:0.25344\n",
      "[508]\tvalidation_0-logloss:0.24425\tvalidation_1-logloss:0.25339\n",
      "[510]\tvalidation_0-logloss:0.24418\tvalidation_1-logloss:0.25334\n",
      "[512]\tvalidation_0-logloss:0.24412\tvalidation_1-logloss:0.25330\n",
      "[514]\tvalidation_0-logloss:0.24405\tvalidation_1-logloss:0.25324\n",
      "[516]\tvalidation_0-logloss:0.24396\tvalidation_1-logloss:0.25320\n",
      "[518]\tvalidation_0-logloss:0.24391\tvalidation_1-logloss:0.25316\n",
      "[520]\tvalidation_0-logloss:0.24385\tvalidation_1-logloss:0.25311\n",
      "[522]\tvalidation_0-logloss:0.24379\tvalidation_1-logloss:0.25307\n",
      "[524]\tvalidation_0-logloss:0.24374\tvalidation_1-logloss:0.25303\n",
      "[526]\tvalidation_0-logloss:0.24368\tvalidation_1-logloss:0.25299\n",
      "[528]\tvalidation_0-logloss:0.24360\tvalidation_1-logloss:0.25295\n",
      "[530]\tvalidation_0-logloss:0.24354\tvalidation_1-logloss:0.25291\n",
      "[532]\tvalidation_0-logloss:0.24348\tvalidation_1-logloss:0.25288\n",
      "[534]\tvalidation_0-logloss:0.24340\tvalidation_1-logloss:0.25285\n",
      "[536]\tvalidation_0-logloss:0.24331\tvalidation_1-logloss:0.25283\n",
      "[538]\tvalidation_0-logloss:0.24324\tvalidation_1-logloss:0.25281\n",
      "[540]\tvalidation_0-logloss:0.24316\tvalidation_1-logloss:0.25278\n",
      "[542]\tvalidation_0-logloss:0.24310\tvalidation_1-logloss:0.25275\n",
      "[544]\tvalidation_0-logloss:0.24301\tvalidation_1-logloss:0.25274\n",
      "[546]\tvalidation_0-logloss:0.24293\tvalidation_1-logloss:0.25271\n",
      "[548]\tvalidation_0-logloss:0.24284\tvalidation_1-logloss:0.25268\n",
      "[550]\tvalidation_0-logloss:0.24278\tvalidation_1-logloss:0.25266\n",
      "[552]\tvalidation_0-logloss:0.24266\tvalidation_1-logloss:0.25265\n",
      "[554]\tvalidation_0-logloss:0.24258\tvalidation_1-logloss:0.25263\n",
      "[556]\tvalidation_0-logloss:0.24251\tvalidation_1-logloss:0.25261\n",
      "[558]\tvalidation_0-logloss:0.24244\tvalidation_1-logloss:0.25259\n",
      "[560]\tvalidation_0-logloss:0.24238\tvalidation_1-logloss:0.25257\n",
      "[562]\tvalidation_0-logloss:0.24232\tvalidation_1-logloss:0.25256\n",
      "[564]\tvalidation_0-logloss:0.24224\tvalidation_1-logloss:0.25255\n",
      "[566]\tvalidation_0-logloss:0.24219\tvalidation_1-logloss:0.25252\n",
      "[568]\tvalidation_0-logloss:0.24211\tvalidation_1-logloss:0.25250\n",
      "[570]\tvalidation_0-logloss:0.24204\tvalidation_1-logloss:0.25248\n",
      "[572]\tvalidation_0-logloss:0.24199\tvalidation_1-logloss:0.25245\n",
      "[574]\tvalidation_0-logloss:0.24196\tvalidation_1-logloss:0.25242\n",
      "[576]\tvalidation_0-logloss:0.24192\tvalidation_1-logloss:0.25240\n",
      "[578]\tvalidation_0-logloss:0.24189\tvalidation_1-logloss:0.25237\n",
      "[580]\tvalidation_0-logloss:0.24184\tvalidation_1-logloss:0.25235\n",
      "[582]\tvalidation_0-logloss:0.24180\tvalidation_1-logloss:0.25233\n",
      "[584]\tvalidation_0-logloss:0.24177\tvalidation_1-logloss:0.25231\n",
      "[586]\tvalidation_0-logloss:0.24175\tvalidation_1-logloss:0.25228\n",
      "[588]\tvalidation_0-logloss:0.24172\tvalidation_1-logloss:0.25226\n",
      "[590]\tvalidation_0-logloss:0.24168\tvalidation_1-logloss:0.25224\n",
      "[592]\tvalidation_0-logloss:0.24164\tvalidation_1-logloss:0.25222\n",
      "[594]\tvalidation_0-logloss:0.24162\tvalidation_1-logloss:0.25220\n",
      "[596]\tvalidation_0-logloss:0.24159\tvalidation_1-logloss:0.25218\n",
      "[598]\tvalidation_0-logloss:0.24156\tvalidation_1-logloss:0.25216\n",
      "[600]\tvalidation_0-logloss:0.24153\tvalidation_1-logloss:0.25214\n",
      "[602]\tvalidation_0-logloss:0.24151\tvalidation_1-logloss:0.25213\n",
      "[604]\tvalidation_0-logloss:0.24149\tvalidation_1-logloss:0.25211\n",
      "[606]\tvalidation_0-logloss:0.24144\tvalidation_1-logloss:0.25210\n",
      "[608]\tvalidation_0-logloss:0.24142\tvalidation_1-logloss:0.25208\n",
      "[610]\tvalidation_0-logloss:0.24139\tvalidation_1-logloss:0.25206\n",
      "[612]\tvalidation_0-logloss:0.24138\tvalidation_1-logloss:0.25205\n",
      "[614]\tvalidation_0-logloss:0.24130\tvalidation_1-logloss:0.25203\n",
      "[616]\tvalidation_0-logloss:0.24127\tvalidation_1-logloss:0.25201\n",
      "[618]\tvalidation_0-logloss:0.24125\tvalidation_1-logloss:0.25200\n",
      "[620]\tvalidation_0-logloss:0.24123\tvalidation_1-logloss:0.25199\n",
      "[622]\tvalidation_0-logloss:0.24121\tvalidation_1-logloss:0.25197\n",
      "[624]\tvalidation_0-logloss:0.24115\tvalidation_1-logloss:0.25195\n",
      "[626]\tvalidation_0-logloss:0.24111\tvalidation_1-logloss:0.25194\n",
      "[628]\tvalidation_0-logloss:0.24107\tvalidation_1-logloss:0.25193\n",
      "[630]\tvalidation_0-logloss:0.24104\tvalidation_1-logloss:0.25192\n",
      "[632]\tvalidation_0-logloss:0.24095\tvalidation_1-logloss:0.25191\n",
      "[634]\tvalidation_0-logloss:0.24094\tvalidation_1-logloss:0.25190\n",
      "[636]\tvalidation_0-logloss:0.24091\tvalidation_1-logloss:0.25188\n",
      "[638]\tvalidation_0-logloss:0.24084\tvalidation_1-logloss:0.25187\n",
      "[640]\tvalidation_0-logloss:0.24082\tvalidation_1-logloss:0.25186\n",
      "[642]\tvalidation_0-logloss:0.24077\tvalidation_1-logloss:0.25184\n",
      "[644]\tvalidation_0-logloss:0.24073\tvalidation_1-logloss:0.25184\n",
      "[646]\tvalidation_0-logloss:0.24067\tvalidation_1-logloss:0.25182\n",
      "[648]\tvalidation_0-logloss:0.24065\tvalidation_1-logloss:0.25181\n",
      "[650]\tvalidation_0-logloss:0.24059\tvalidation_1-logloss:0.25181\n",
      "[652]\tvalidation_0-logloss:0.24055\tvalidation_1-logloss:0.25180\n",
      "[654]\tvalidation_0-logloss:0.24048\tvalidation_1-logloss:0.25180\n",
      "[656]\tvalidation_0-logloss:0.24046\tvalidation_1-logloss:0.25179\n",
      "[658]\tvalidation_0-logloss:0.24040\tvalidation_1-logloss:0.25179\n",
      "[660]\tvalidation_0-logloss:0.24033\tvalidation_1-logloss:0.25178\n",
      "[662]\tvalidation_0-logloss:0.24030\tvalidation_1-logloss:0.25178\n",
      "[664]\tvalidation_0-logloss:0.24026\tvalidation_1-logloss:0.25177\n",
      "[666]\tvalidation_0-logloss:0.24024\tvalidation_1-logloss:0.25177\n",
      "[668]\tvalidation_0-logloss:0.24021\tvalidation_1-logloss:0.25176\n",
      "[670]\tvalidation_0-logloss:0.24018\tvalidation_1-logloss:0.25176\n",
      "[672]\tvalidation_0-logloss:0.24015\tvalidation_1-logloss:0.25176\n",
      "[674]\tvalidation_0-logloss:0.24012\tvalidation_1-logloss:0.25175\n",
      "[676]\tvalidation_0-logloss:0.24009\tvalidation_1-logloss:0.25176\n",
      "[678]\tvalidation_0-logloss:0.24007\tvalidation_1-logloss:0.25175\n",
      "[680]\tvalidation_0-logloss:0.24002\tvalidation_1-logloss:0.25174\n",
      "[682]\tvalidation_0-logloss:0.24000\tvalidation_1-logloss:0.25174\n",
      "[684]\tvalidation_0-logloss:0.23998\tvalidation_1-logloss:0.25173\n",
      "[686]\tvalidation_0-logloss:0.23994\tvalidation_1-logloss:0.25173\n",
      "[688]\tvalidation_0-logloss:0.23991\tvalidation_1-logloss:0.25173\n",
      "[690]\tvalidation_0-logloss:0.23987\tvalidation_1-logloss:0.25172\n",
      "[692]\tvalidation_0-logloss:0.23985\tvalidation_1-logloss:0.25171\n",
      "[694]\tvalidation_0-logloss:0.23979\tvalidation_1-logloss:0.25170\n",
      "[696]\tvalidation_0-logloss:0.23977\tvalidation_1-logloss:0.25170\n",
      "[698]\tvalidation_0-logloss:0.23969\tvalidation_1-logloss:0.25170\n",
      "[700]\tvalidation_0-logloss:0.23967\tvalidation_1-logloss:0.25169\n",
      "[702]\tvalidation_0-logloss:0.23961\tvalidation_1-logloss:0.25169\n",
      "[704]\tvalidation_0-logloss:0.23956\tvalidation_1-logloss:0.25168\n",
      "[706]\tvalidation_0-logloss:0.23951\tvalidation_1-logloss:0.25168\n",
      "[708]\tvalidation_0-logloss:0.23945\tvalidation_1-logloss:0.25168\n",
      "[710]\tvalidation_0-logloss:0.23939\tvalidation_1-logloss:0.25167\n",
      "[712]\tvalidation_0-logloss:0.23935\tvalidation_1-logloss:0.25167\n",
      "[714]\tvalidation_0-logloss:0.23930\tvalidation_1-logloss:0.25167\n",
      "[716]\tvalidation_0-logloss:0.23927\tvalidation_1-logloss:0.25167\n",
      "[718]\tvalidation_0-logloss:0.23922\tvalidation_1-logloss:0.25166\n",
      "[720]\tvalidation_0-logloss:0.23921\tvalidation_1-logloss:0.25165\n",
      "[722]\tvalidation_0-logloss:0.23916\tvalidation_1-logloss:0.25165\n",
      "[724]\tvalidation_0-logloss:0.23910\tvalidation_1-logloss:0.25165\n",
      "[726]\tvalidation_0-logloss:0.23908\tvalidation_1-logloss:0.25164\n",
      "[728]\tvalidation_0-logloss:0.23902\tvalidation_1-logloss:0.25164\n",
      "[730]\tvalidation_0-logloss:0.23900\tvalidation_1-logloss:0.25163\n",
      "[732]\tvalidation_0-logloss:0.23894\tvalidation_1-logloss:0.25163\n",
      "[734]\tvalidation_0-logloss:0.23888\tvalidation_1-logloss:0.25162\n",
      "[736]\tvalidation_0-logloss:0.23885\tvalidation_1-logloss:0.25162\n",
      "[738]\tvalidation_0-logloss:0.23879\tvalidation_1-logloss:0.25162\n",
      "[740]\tvalidation_0-logloss:0.23871\tvalidation_1-logloss:0.25161\n",
      "[742]\tvalidation_0-logloss:0.23870\tvalidation_1-logloss:0.25161\n",
      "[744]\tvalidation_0-logloss:0.23867\tvalidation_1-logloss:0.25160\n",
      "[746]\tvalidation_0-logloss:0.23861\tvalidation_1-logloss:0.25160\n",
      "[748]\tvalidation_0-logloss:0.23855\tvalidation_1-logloss:0.25160\n",
      "[750]\tvalidation_0-logloss:0.23854\tvalidation_1-logloss:0.25160\n",
      "[752]\tvalidation_0-logloss:0.23846\tvalidation_1-logloss:0.25158\n",
      "[754]\tvalidation_0-logloss:0.23844\tvalidation_1-logloss:0.25158\n",
      "[756]\tvalidation_0-logloss:0.23841\tvalidation_1-logloss:0.25158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[758]\tvalidation_0-logloss:0.23836\tvalidation_1-logloss:0.25157\n",
      "[760]\tvalidation_0-logloss:0.23833\tvalidation_1-logloss:0.25156\n",
      "[762]\tvalidation_0-logloss:0.23830\tvalidation_1-logloss:0.25156\n",
      "[764]\tvalidation_0-logloss:0.23825\tvalidation_1-logloss:0.25155\n",
      "[766]\tvalidation_0-logloss:0.23821\tvalidation_1-logloss:0.25155\n",
      "[768]\tvalidation_0-logloss:0.23818\tvalidation_1-logloss:0.25155\n",
      "[770]\tvalidation_0-logloss:0.23815\tvalidation_1-logloss:0.25155\n",
      "[772]\tvalidation_0-logloss:0.23810\tvalidation_1-logloss:0.25154\n",
      "[774]\tvalidation_0-logloss:0.23808\tvalidation_1-logloss:0.25154\n",
      "[776]\tvalidation_0-logloss:0.23807\tvalidation_1-logloss:0.25154\n",
      "[778]\tvalidation_0-logloss:0.23800\tvalidation_1-logloss:0.25153\n",
      "[780]\tvalidation_0-logloss:0.23796\tvalidation_1-logloss:0.25153\n",
      "[782]\tvalidation_0-logloss:0.23795\tvalidation_1-logloss:0.25152\n",
      "[784]\tvalidation_0-logloss:0.23791\tvalidation_1-logloss:0.25152\n",
      "[786]\tvalidation_0-logloss:0.23785\tvalidation_1-logloss:0.25152\n",
      "[788]\tvalidation_0-logloss:0.23783\tvalidation_1-logloss:0.25152\n",
      "[790]\tvalidation_0-logloss:0.23779\tvalidation_1-logloss:0.25152\n",
      "[792]\tvalidation_0-logloss:0.23778\tvalidation_1-logloss:0.25152\n",
      "[794]\tvalidation_0-logloss:0.23775\tvalidation_1-logloss:0.25151\n",
      "[796]\tvalidation_0-logloss:0.23770\tvalidation_1-logloss:0.25151\n",
      "[798]\tvalidation_0-logloss:0.23766\tvalidation_1-logloss:0.25151\n",
      "[800]\tvalidation_0-logloss:0.23763\tvalidation_1-logloss:0.25151\n",
      "[802]\tvalidation_0-logloss:0.23758\tvalidation_1-logloss:0.25151\n",
      "[804]\tvalidation_0-logloss:0.23754\tvalidation_1-logloss:0.25150\n",
      "[806]\tvalidation_0-logloss:0.23753\tvalidation_1-logloss:0.25150\n",
      "[808]\tvalidation_0-logloss:0.23747\tvalidation_1-logloss:0.25150\n",
      "[810]\tvalidation_0-logloss:0.23746\tvalidation_1-logloss:0.25150\n",
      "[812]\tvalidation_0-logloss:0.23742\tvalidation_1-logloss:0.25149\n",
      "[814]\tvalidation_0-logloss:0.23738\tvalidation_1-logloss:0.25149\n",
      "[816]\tvalidation_0-logloss:0.23737\tvalidation_1-logloss:0.25149\n",
      "[818]\tvalidation_0-logloss:0.23732\tvalidation_1-logloss:0.25149\n",
      "[820]\tvalidation_0-logloss:0.23729\tvalidation_1-logloss:0.25150\n",
      "[822]\tvalidation_0-logloss:0.23725\tvalidation_1-logloss:0.25149\n",
      "[824]\tvalidation_0-logloss:0.23721\tvalidation_1-logloss:0.25150\n",
      "[826]\tvalidation_0-logloss:0.23717\tvalidation_1-logloss:0.25150\n",
      "[828]\tvalidation_0-logloss:0.23715\tvalidation_1-logloss:0.25149\n",
      "[830]\tvalidation_0-logloss:0.23712\tvalidation_1-logloss:0.25149\n",
      "[832]\tvalidation_0-logloss:0.23710\tvalidation_1-logloss:0.25149\n",
      "[834]\tvalidation_0-logloss:0.23709\tvalidation_1-logloss:0.25149\n",
      "[836]\tvalidation_0-logloss:0.23704\tvalidation_1-logloss:0.25149\n",
      "[838]\tvalidation_0-logloss:0.23702\tvalidation_1-logloss:0.25148\n",
      "[840]\tvalidation_0-logloss:0.23700\tvalidation_1-logloss:0.25148\n",
      "[842]\tvalidation_0-logloss:0.23699\tvalidation_1-logloss:0.25148\n",
      "[844]\tvalidation_0-logloss:0.23697\tvalidation_1-logloss:0.25148\n",
      "[846]\tvalidation_0-logloss:0.23689\tvalidation_1-logloss:0.25148\n",
      "[848]\tvalidation_0-logloss:0.23687\tvalidation_1-logloss:0.25148\n",
      "[850]\tvalidation_0-logloss:0.23685\tvalidation_1-logloss:0.25148\n",
      "[852]\tvalidation_0-logloss:0.23682\tvalidation_1-logloss:0.25148\n",
      "[854]\tvalidation_0-logloss:0.23681\tvalidation_1-logloss:0.25148\n",
      "[856]\tvalidation_0-logloss:0.23679\tvalidation_1-logloss:0.25148\n",
      "[858]\tvalidation_0-logloss:0.23674\tvalidation_1-logloss:0.25148\n",
      "[860]\tvalidation_0-logloss:0.23672\tvalidation_1-logloss:0.25148\n",
      "[862]\tvalidation_0-logloss:0.23670\tvalidation_1-logloss:0.25147\n",
      "[864]\tvalidation_0-logloss:0.23667\tvalidation_1-logloss:0.25147\n",
      "[866]\tvalidation_0-logloss:0.23662\tvalidation_1-logloss:0.25147\n",
      "[868]\tvalidation_0-logloss:0.23658\tvalidation_1-logloss:0.25148\n",
      "[870]\tvalidation_0-logloss:0.23657\tvalidation_1-logloss:0.25148\n",
      "[872]\tvalidation_0-logloss:0.23651\tvalidation_1-logloss:0.25148\n",
      "[874]\tvalidation_0-logloss:0.23650\tvalidation_1-logloss:0.25148\n",
      "[876]\tvalidation_0-logloss:0.23648\tvalidation_1-logloss:0.25148\n",
      "[878]\tvalidation_0-logloss:0.23643\tvalidation_1-logloss:0.25148\n",
      "[880]\tvalidation_0-logloss:0.23640\tvalidation_1-logloss:0.25148\n",
      "[882]\tvalidation_0-logloss:0.23638\tvalidation_1-logloss:0.25147\n",
      "[884]\tvalidation_0-logloss:0.23635\tvalidation_1-logloss:0.25147\n",
      "[886]\tvalidation_0-logloss:0.23632\tvalidation_1-logloss:0.25147\n",
      "[888]\tvalidation_0-logloss:0.23630\tvalidation_1-logloss:0.25148\n",
      "[890]\tvalidation_0-logloss:0.23627\tvalidation_1-logloss:0.25148\n",
      "[892]\tvalidation_0-logloss:0.23625\tvalidation_1-logloss:0.25148\n",
      "[894]\tvalidation_0-logloss:0.23621\tvalidation_1-logloss:0.25148\n",
      "[896]\tvalidation_0-logloss:0.23620\tvalidation_1-logloss:0.25148\n",
      "[898]\tvalidation_0-logloss:0.23615\tvalidation_1-logloss:0.25148\n",
      "[900]\tvalidation_0-logloss:0.23613\tvalidation_1-logloss:0.25148\n",
      "[902]\tvalidation_0-logloss:0.23611\tvalidation_1-logloss:0.25148\n",
      "[904]\tvalidation_0-logloss:0.23608\tvalidation_1-logloss:0.25147\n",
      "[906]\tvalidation_0-logloss:0.23604\tvalidation_1-logloss:0.25148\n",
      "[908]\tvalidation_0-logloss:0.23603\tvalidation_1-logloss:0.25148\n",
      "[910]\tvalidation_0-logloss:0.23600\tvalidation_1-logloss:0.25148\n",
      "[912]\tvalidation_0-logloss:0.23594\tvalidation_1-logloss:0.25149\n",
      "[914]\tvalidation_0-logloss:0.23591\tvalidation_1-logloss:0.25149\n",
      "[916]\tvalidation_0-logloss:0.23591\tvalidation_1-logloss:0.25149\n",
      "[918]\tvalidation_0-logloss:0.23585\tvalidation_1-logloss:0.25149\n",
      "[920]\tvalidation_0-logloss:0.23584\tvalidation_1-logloss:0.25149\n",
      "[922]\tvalidation_0-logloss:0.23582\tvalidation_1-logloss:0.25149\n",
      "[924]\tvalidation_0-logloss:0.23580\tvalidation_1-logloss:0.25150\n",
      "[926]\tvalidation_0-logloss:0.23575\tvalidation_1-logloss:0.25150\n",
      "[928]\tvalidation_0-logloss:0.23571\tvalidation_1-logloss:0.25150\n",
      "[930]\tvalidation_0-logloss:0.23570\tvalidation_1-logloss:0.25150\n",
      "[932]\tvalidation_0-logloss:0.23569\tvalidation_1-logloss:0.25150\n",
      "[934]\tvalidation_0-logloss:0.23566\tvalidation_1-logloss:0.25150\n",
      "[936]\tvalidation_0-logloss:0.23565\tvalidation_1-logloss:0.25151\n",
      "[938]\tvalidation_0-logloss:0.23558\tvalidation_1-logloss:0.25151\n",
      "[940]\tvalidation_0-logloss:0.23556\tvalidation_1-logloss:0.25151\n",
      "[942]\tvalidation_0-logloss:0.23553\tvalidation_1-logloss:0.25151\n",
      "[944]\tvalidation_0-logloss:0.23549\tvalidation_1-logloss:0.25151\n",
      "[946]\tvalidation_0-logloss:0.23547\tvalidation_1-logloss:0.25151\n",
      "[948]\tvalidation_0-logloss:0.23545\tvalidation_1-logloss:0.25151\n",
      "[950]\tvalidation_0-logloss:0.23542\tvalidation_1-logloss:0.25151\n",
      "[952]\tvalidation_0-logloss:0.23541\tvalidation_1-logloss:0.25151\n",
      "[954]\tvalidation_0-logloss:0.23536\tvalidation_1-logloss:0.25151\n",
      "[956]\tvalidation_0-logloss:0.23535\tvalidation_1-logloss:0.25151\n",
      "[958]\tvalidation_0-logloss:0.23532\tvalidation_1-logloss:0.25152\n",
      "[960]\tvalidation_0-logloss:0.23530\tvalidation_1-logloss:0.25152\n",
      "[962]\tvalidation_0-logloss:0.23523\tvalidation_1-logloss:0.25152\n",
      "[964]\tvalidation_0-logloss:0.23521\tvalidation_1-logloss:0.25153\n",
      "[966]\tvalidation_0-logloss:0.23520\tvalidation_1-logloss:0.25153\n",
      "[968]\tvalidation_0-logloss:0.23514\tvalidation_1-logloss:0.25153\n",
      "[970]\tvalidation_0-logloss:0.23511\tvalidation_1-logloss:0.25154\n",
      "[972]\tvalidation_0-logloss:0.23509\tvalidation_1-logloss:0.25154\n",
      "[974]\tvalidation_0-logloss:0.23507\tvalidation_1-logloss:0.25153\n",
      "[976]\tvalidation_0-logloss:0.23503\tvalidation_1-logloss:0.25153\n",
      "[978]\tvalidation_0-logloss:0.23502\tvalidation_1-logloss:0.25154\n",
      "[980]\tvalidation_0-logloss:0.23499\tvalidation_1-logloss:0.25154\n",
      "[982]\tvalidation_0-logloss:0.23498\tvalidation_1-logloss:0.25154\n",
      "[984]\tvalidation_0-logloss:0.23496\tvalidation_1-logloss:0.25154\n",
      "[986]\tvalidation_0-logloss:0.23490\tvalidation_1-logloss:0.25154\n",
      "[988]\tvalidation_0-logloss:0.23486\tvalidation_1-logloss:0.25154\n",
      "[990]\tvalidation_0-logloss:0.23483\tvalidation_1-logloss:0.25154\n",
      "[992]\tvalidation_0-logloss:0.23481\tvalidation_1-logloss:0.25154\n",
      "[994]\tvalidation_0-logloss:0.23479\tvalidation_1-logloss:0.25155\n",
      "[996]\tvalidation_0-logloss:0.23474\tvalidation_1-logloss:0.25155\n",
      "[998]\tvalidation_0-logloss:0.23470\tvalidation_1-logloss:0.25155\n",
      "[1000]\tvalidation_0-logloss:0.23467\tvalidation_1-logloss:0.25156\n",
      "[1002]\tvalidation_0-logloss:0.23464\tvalidation_1-logloss:0.25155\n",
      "[1004]\tvalidation_0-logloss:0.23463\tvalidation_1-logloss:0.25156\n",
      "[1006]\tvalidation_0-logloss:0.23458\tvalidation_1-logloss:0.25156\n",
      "[1008]\tvalidation_0-logloss:0.23456\tvalidation_1-logloss:0.25156\n",
      "[1010]\tvalidation_0-logloss:0.23455\tvalidation_1-logloss:0.25156\n",
      "[1012]\tvalidation_0-logloss:0.23453\tvalidation_1-logloss:0.25157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1014]\tvalidation_0-logloss:0.23448\tvalidation_1-logloss:0.25157\n",
      "[1016]\tvalidation_0-logloss:0.23444\tvalidation_1-logloss:0.25158\n",
      "[1018]\tvalidation_0-logloss:0.23441\tvalidation_1-logloss:0.25158\n",
      "[1020]\tvalidation_0-logloss:0.23437\tvalidation_1-logloss:0.25158\n",
      "[1022]\tvalidation_0-logloss:0.23434\tvalidation_1-logloss:0.25158\n",
      "[1024]\tvalidation_0-logloss:0.23431\tvalidation_1-logloss:0.25159\n",
      "[1026]\tvalidation_0-logloss:0.23430\tvalidation_1-logloss:0.25159\n",
      "[1028]\tvalidation_0-logloss:0.23428\tvalidation_1-logloss:0.25159\n",
      "[1030]\tvalidation_0-logloss:0.23425\tvalidation_1-logloss:0.25159\n",
      "[1032]\tvalidation_0-logloss:0.23422\tvalidation_1-logloss:0.25160\n",
      "[1034]\tvalidation_0-logloss:0.23419\tvalidation_1-logloss:0.25160\n",
      "[1036]\tvalidation_0-logloss:0.23417\tvalidation_1-logloss:0.25160\n",
      "[1038]\tvalidation_0-logloss:0.23414\tvalidation_1-logloss:0.25161\n",
      "[1040]\tvalidation_0-logloss:0.23412\tvalidation_1-logloss:0.25161\n",
      "[1042]\tvalidation_0-logloss:0.23408\tvalidation_1-logloss:0.25161\n",
      "[1044]\tvalidation_0-logloss:0.23406\tvalidation_1-logloss:0.25161\n",
      "[1046]\tvalidation_0-logloss:0.23403\tvalidation_1-logloss:0.25161\n",
      "[1048]\tvalidation_0-logloss:0.23399\tvalidation_1-logloss:0.25162\n",
      "[1050]\tvalidation_0-logloss:0.23395\tvalidation_1-logloss:0.25162\n",
      "[1052]\tvalidation_0-logloss:0.23393\tvalidation_1-logloss:0.25162\n",
      "[1054]\tvalidation_0-logloss:0.23389\tvalidation_1-logloss:0.25163\n",
      "[1056]\tvalidation_0-logloss:0.23386\tvalidation_1-logloss:0.25163\n",
      "[1058]\tvalidation_0-logloss:0.23382\tvalidation_1-logloss:0.25164\n",
      "[1060]\tvalidation_0-logloss:0.23380\tvalidation_1-logloss:0.25164\n",
      "Stopping. Best iteration:\n",
      "[861]\tvalidation_0-logloss:0.23671\tvalidation_1-logloss:0.25147\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.7, booster='gbtree', boosting_type='gbtree',\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             gamma=0, gpu_id=-1, importance_type='gain',\n",
       "             interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
       "             max_depth=12, max_features='auto', min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=5000, n_jobs=0,\n",
       "             num_parallel_tree=1, objective='reg:logistic', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = xgb.XGBRegressor(objective='reg:logistic',\n",
    "                       boosting_type='gbtree', \n",
    "                       learning_rate=0.01, \n",
    "                       n_estimators=5000, \n",
    "                       max_depth=12, \n",
    "                       base_score=0.7,\n",
    "                       max_features='auto'\n",
    "                     )\n",
    "\n",
    "eval_set = [(x_train, y_train), (x_test1, y_test1)]\n",
    "xg.fit(x_train, y_train, eval_metric=\"logloss\", eval_set=eval_set, verbose=2, early_stopping_rounds = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01095049, 0.00063961, 0.00334022, ..., 0.4377475 , 0.00824863,\n",
       "       0.0017257 ], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = xg.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01472769, 0.00417481, 0.00686549, 0.        , 0.00359419,\n",
       "       0.00525797, 0.00744865, 0.00366122, 0.17620459, 0.0033633 ,\n",
       "       0.00393874, 0.21291384, 0.05019363, 0.04469667, 0.04809345,\n",
       "       0.04519153, 0.01073598, 0.04333963, 0.0432976 , 0.04234079,\n",
       "       0.04532566, 0.01489232, 0.04133054, 0.06576986, 0.03952994,\n",
       "       0.00473798, 0.00227702, 0.00201783, 0.00363686, 0.0024629 ,\n",
       "       0.00209837, 0.00189387, 0.00398702], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Feature Importance Score')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_imp = pd.Series(xg.feature_importances_).sort_values(ascending=False)\n",
    "plt.figure(figsize=(12,8))\n",
    "feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the predictions make into the sample file for submission\n",
    "\n",
    "preds1 = xg.predict(test_enc)\n",
    "sample1 = pd.read_csv('sample_submission.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "sample1.user_id = test.user_id\n",
    "sample1.CHURN = preds1\n",
    "sample1.to_csv('XG.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTANT</th>\n",
       "      <th>FREQUENCE_RECH</th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>ARPU_SEGMENT</th>\n",
       "      <th>FREQUENCE</th>\n",
       "      <th>DATA_VOLUME</th>\n",
       "      <th>ON_NET</th>\n",
       "      <th>ORANGE</th>\n",
       "      <th>REGULARITY</th>\n",
       "      <th>TOP_PACK</th>\n",
       "      <th>...</th>\n",
       "      <th>REGION_THIES</th>\n",
       "      <th>REGION_ZIGUINCHOR</th>\n",
       "      <th>TENURE_D 3-6 month</th>\n",
       "      <th>TENURE_E 6-9 month</th>\n",
       "      <th>TENURE_F 9-12 month</th>\n",
       "      <th>TENURE_G 12-15 month</th>\n",
       "      <th>TENURE_H 15-18 month</th>\n",
       "      <th>TENURE_I 18-21 month</th>\n",
       "      <th>TENURE_J 21-24 month</th>\n",
       "      <th>TENURE_K &gt; 24 month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.146687</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4300.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4427.0</td>\n",
       "      <td>1476.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.038975</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.146687</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2497.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.070968</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.418322</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTANT  FREQUENCE_RECH  REVENUE  ARPU_SEGMENT  FREQUENCE  DATA_VOLUME  \\\n",
       "0  17000.0            32.0  18000.0        6000.0       34.0       -999.0   \n",
       "1   4300.0            29.0   4427.0        1476.0       37.0       1764.0   \n",
       "2   1500.0             3.0   1500.0         500.0        3.0       -999.0   \n",
       "3   1500.0             3.0   2497.0         832.0        4.0          0.0   \n",
       "4   -999.0          -999.0    498.0         166.0        3.0          1.0   \n",
       "\n",
       "   ON_NET  ORANGE  REGULARITY  TOP_PACK  ...  REGION_THIES  REGION_ZIGUINCHOR  \\\n",
       "0    97.0   355.0          62  0.146687  ...             0                  0   \n",
       "1     8.0     3.0          40  0.038975  ...             0                  0   \n",
       "2    30.0    30.0          32  0.146687  ...             0                  0   \n",
       "3   159.0    45.0          18  0.070968  ...             0                  0   \n",
       "4     1.0     3.0          50  0.418322  ...             0                  0   \n",
       "\n",
       "   TENURE_D 3-6 month  TENURE_E 6-9 month  TENURE_F 9-12 month  \\\n",
       "0                   0                   0                    0   \n",
       "1                   0                   0                    0   \n",
       "2                   0                   0                    0   \n",
       "3                   0                   0                    0   \n",
       "4                   0                   0                    0   \n",
       "\n",
       "   TENURE_G 12-15 month  TENURE_H 15-18 month  TENURE_I 18-21 month  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   TENURE_J 21-24 month  TENURE_K > 24 month  \n",
       "0                     0                    1  \n",
       "1                     0                    1  \n",
       "2                     0                    1  \n",
       "3                     0                    1  \n",
       "4                     0                    1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MONTANT', 'FREQUENCE_RECH', 'REVENUE', 'ARPU_SEGMENT', 'FREQUENCE',\n",
       "       'DATA_VOLUME', 'ON_NET', 'ORANGE', 'REGULARITY', 'TOP_PACK',\n",
       "       'FREQ_TOP_PACK', 'REGION_DAKAR', 'REGION_DIOURBEL', 'REGION_FATICK',\n",
       "       'REGION_KAFFRINE', 'REGION_KAOLACK', 'REGION_KEDOUGOU', 'REGION_KOLDA',\n",
       "       'REGION_LOUGA', 'REGION_MATAM', 'REGION_SAINT-LOUIS', 'REGION_SEDHIOU',\n",
       "       'REGION_TAMBACOUNDA', 'REGION_THIES', 'REGION_ZIGUINCHOR',\n",
       "       'TENURE_D 3-6 month', 'TENURE_E 6-9 month', 'TENURE_F 9-12 month',\n",
       "       'TENURE_G 12-15 month', 'TENURE_H 15-18 month', 'TENURE_I 18-21 month',\n",
       "       'TENURE_J 21-24 month', 'TENURE_K > 24 month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MONTANT                 float64\n",
       "FREQUENCE_RECH          float64\n",
       "REVENUE                 float64\n",
       "ARPU_SEGMENT            float64\n",
       "FREQUENCE               float64\n",
       "DATA_VOLUME             float64\n",
       "ON_NET                  float64\n",
       "ORANGE                  float64\n",
       "REGULARITY                int64\n",
       "TOP_PACK                float64\n",
       "FREQ_TOP_PACK           float64\n",
       "REGION_DAKAR              uint8\n",
       "REGION_DIOURBEL           uint8\n",
       "REGION_FATICK             uint8\n",
       "REGION_KAFFRINE           uint8\n",
       "REGION_KAOLACK            uint8\n",
       "REGION_KEDOUGOU           uint8\n",
       "REGION_KOLDA              uint8\n",
       "REGION_LOUGA              uint8\n",
       "REGION_MATAM              uint8\n",
       "REGION_SAINT-LOUIS        uint8\n",
       "REGION_SEDHIOU            uint8\n",
       "REGION_TAMBACOUNDA        uint8\n",
       "REGION_THIES              uint8\n",
       "REGION_ZIGUINCHOR         uint8\n",
       "TENURE_D 3-6 month        uint8\n",
       "TENURE_E 6-9 month        uint8\n",
       "TENURE_F 9-12 month       uint8\n",
       "TENURE_G 12-15 month      uint8\n",
       "TENURE_H 15-18 month      uint8\n",
       "TENURE_I 18-21 month      uint8\n",
       "TENURE_J 21-24 month      uint8\n",
       "TENURE_K > 24 month       uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-3401159009c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHURN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sample1' is not defined"
     ]
    }
   ],
   "source": [
    "sample1.CHURN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
