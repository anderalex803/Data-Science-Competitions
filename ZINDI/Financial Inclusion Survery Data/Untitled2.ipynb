{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as sklm\n",
    "import xgboost as xgb\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('trainreg.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submissions = pd.read_csv('submissionfile.csv')\n",
    "vd = pd.read_csv('VariableDefinitions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_string(data):\n",
    "    enc = preprocessing.LabelEncoder()\n",
    "    enc.fit(data)\n",
    "    enc_features = enc.transform(data)\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    encoded = ohe.fit(enc_features.reshape(-1,1))\n",
    "    return encoded.transform(enc_features.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23524, 37)\n",
      "(10086, 37)\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['location_type', 'cellphone_access', 'gender_of_respondent', 'relationship_with_head',\n",
    "                       'marital_status', 'education_level', 'job_type']\n",
    "\n",
    "Features_enc = encode_string(train['country'])\n",
    "for col in categorical_columns:\n",
    "    temp = encode_string(train[col])\n",
    "    Features_enc = np.concatenate([Features_enc, temp], axis = 1)\n",
    "    \n",
    "print(Features_enc.shape)\n",
    "\n",
    "test_enc = encode_string(test['country'])\n",
    "for col in categorical_columns:\n",
    "    temp1 = encode_string(test[col])\n",
    "    test_enc = np.concatenate([test_enc, temp1], axis = 1)\n",
    "    \n",
    "print(test_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23524, 40)\n",
      "(10086, 40)\n"
     ]
    }
   ],
   "source": [
    "Features_enc = np.concatenate([Features_enc, np.array(train[['household_size', 'age_of_respondent', 'year']])], axis = 1)\n",
    "print(Features_enc.shape)\n",
    "\n",
    "test_enc = np.concatenate([test_enc, np.array(test[['household_size', 'age_of_respondent', 'year']])], axis = 1)\n",
    "print(test_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          1.         -0.35800673 -0.89618796  1.20854126]\n",
      " [ 0.          0.          0.53983446  1.88827897  1.20854126]\n",
      " [ 0.          1.          0.53983446 -0.77512418  1.20854126]\n",
      " [ 0.          0.          0.53983446 -0.29086906  1.20854126]\n",
      " [ 0.          0.          1.88659625 -0.77512418  1.20854126]]\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(Features_enc[:, 37:40])\n",
    "Features_enc[:, 37:40] = scaler.transform(Features_enc[:, 37:40])\n",
    "print(Features_enc[:5, 35:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.         -0.35198335 -0.51067812  1.20863498]\n",
      " [ 0.          0.          1.45583541  0.78010077  1.20863498]\n",
      " [ 1.          0.         -0.35198335  2.37820797  1.20863498]\n",
      " [ 1.          0.          1.00388072  0.04251284  1.20863498]\n",
      " [ 1.          0.         -0.35198335 -1.37119738  1.20863498]]\n"
     ]
    }
   ],
   "source": [
    "scaler1 = preprocessing.StandardScaler().fit(test_enc[:, 37:40])\n",
    "test_enc[:, 37:40] = scaler1.transform(test_enc[:, 37:40])\n",
    "print(test_enc[:5, 35:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 46.       47.       48.      ... 715.88328 716.88328 717.88328]\n"
     ]
    }
   ],
   "source": [
    "Labels = np.array(train['bank_account'])\n",
    "print(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as nr\n",
    "import sklearn.model_selection as ms\n",
    "## Randomly sample cases to create independent training and test data\n",
    "nr.seed(9988)\n",
    "indx = range(Features_enc.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 0.2)\n",
    "x_train = Features_enc[indx[0],:]\n",
    "y_train = np.ravel(Labels[indx[0]])\n",
    "x_test = Features_enc[indx[1],:]\n",
    "y_test = np.ravel(Labels[indx[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx1 = range(x_train.shape[0])\n",
    "indx1 = ms.train_test_split(indx1, test_size = 0.2)\n",
    "x_train1 = x_train[indx1[0],:]\n",
    "y_train1 = np.ravel(y_train[indx1[0]])\n",
    "x_train_val = x_train[indx1[1],:]\n",
    "y_train_val = np.ravel(y_train[indx1[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18819, 40)\n",
      "(15055, 40)\n",
      "(3764, 40)\n",
      "(18819,)\n",
      "(15055,)\n",
      "(3764,)\n",
      "(4705, 40)\n",
      "(4705,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_train1.shape)\n",
    "print(x_train_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train1.shape)\n",
    "print(y_train_val.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_cl1 = xgb.XGBRegressor(objective = 'reg:logistic', n_estimators = 4000, seed = 123, max_depth = 8,\n",
    "                           learning_rate=0.01, booster = 'gbtree', base_score = 0.8, subsample = 0.8,\n",
    "                           reg_lambda = 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_format(f, x, y, z):\n",
    "    print('Fold %1d     %4.3f         %4.3f        %4.3f'  %  (f, x, y, z))\n",
    "    \n",
    "def print_metrics(labels, scores):\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                  Confusion matrix')\n",
    "    print('                 Score positive     Score negative')\n",
    "    print('True positive    %6d' % conf[0,0] + '            %5d' % conf[0,1])\n",
    "    print('True negative    %6d' % conf[1,0] + '            %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Incorrect    %0.2f' % (1 - (sklm.accuracy_score(labels, scores))))\n",
    "    print('')\n",
    "    print('              Positive    Negative')\n",
    "    print('Num case     %0.2f' % metrics[3][0] + '       %0.2f' % metrics[3][1])\n",
    "    print('Precision       %0.2f' % metrics[0][0] + '       %0.2f' % metrics[0][1])\n",
    "    print('Recall          %0.2f' % metrics[1][0] + '       %0.2f' % metrics[1][1])\n",
    "    print('F1              %0.2f' % metrics[2][0] + '       %0.2f' % metrics[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cv(scores):\n",
    "    fold = [x + 1 for x in range(len(scores['test_precision_macro']))]\n",
    "    print('         Precision     Recall,   AUC')\n",
    "    [print_format(f,x,y,z) for f,x,y,z in zip(fold, scores['test_precision_macro'],\n",
    "                                             scores['test_recall_macro'],\n",
    "                                             scores['test_roc_auc'])]\n",
    "    print('-' * 40)\n",
    "    print('Mean     %4.3f        %4.3f        %4.3f'  %\n",
    "         (np.mean(scores['test_precision_macro']), np.mean(scores['test_recall_macro']), np.mean(scores['test_roc_auc'])))\n",
    "    print('Std      %4.3f        %4.3f      %4.3f'    %\n",
    "         (np.std(scores['test_precision_macro']), np.std(scores['test_recall_macro']), np.std(scores['test_roc_auc'])))\n",
    "    \n",
    "#print_cv(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=12,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=5,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=200, max_depth=12, min_samples_split=5)\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=12,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=5,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf.predict(x_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-4cc950d76975>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-e39f002b7350>\u001b[0m in \u001b[0;36mprint_metrics\u001b[1;34m(labels, scores)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprint_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mconf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'                  Confusion matrix'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1025\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1026\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import root_me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
